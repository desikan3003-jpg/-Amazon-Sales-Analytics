{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9266c527",
   "metadata": {},
   "source": [
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074fbe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded: (33165, 34)\n",
      "üóìÔ∏è Date column cleaned.\n",
      "üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\n",
      "üí∞ Price columns cleaned and converted to numeric.\n",
      "‚≠ê Ratings standardized to numeric scale.\n",
      "üèôÔ∏è City names standardized.\n",
      "üîò Boolean columns standardized to True/False.\n",
      "üõí Product categories standardized.\n",
      "üöö Delivery days cleaned and standardized.\n",
      "üîÅ Smart duplicate handling applied (bulk, error, uncertain).\n",
      "üìà Outlier prices detected and corrected using statistical + category rules.\n",
      "üí≥ Payment methods standardized.\n",
      "üë§ Age column cleaned. Missing and unknown values filled with average: 32\n",
      "üéâ Festival names missing values filled with 'Unknown'.\n",
      "üí∞ Delivery charges missing values replaced with 0.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33164 entries, 0 to 33163\n",
      "Data columns (total 38 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   transaction_id          33164 non-null  object \n",
      " 1   order_date              33164 non-null  object \n",
      " 2   customer_id             33164 non-null  object \n",
      " 3   product_id              33164 non-null  object \n",
      " 4   product_name            33164 non-null  object \n",
      " 5   category                33164 non-null  object \n",
      " 6   subcategory             33164 non-null  object \n",
      " 7   brand                   33164 non-null  object \n",
      " 8   original_price_inr      32177 non-null  float64\n",
      " 9   discount_percent        33164 non-null  float64\n",
      " 10  discounted_price_inr    33164 non-null  float64\n",
      " 11  quantity                33164 non-null  int64  \n",
      " 12  subtotal_inr            33164 non-null  float64\n",
      " 13  delivery_charges        33164 non-null  float64\n",
      " 14  final_amount_inr        33164 non-null  float64\n",
      " 15  customer_city           33164 non-null  object \n",
      " 16  customer_state          33164 non-null  object \n",
      " 17  customer_tier           33164 non-null  object \n",
      " 18  customer_spending_tier  33164 non-null  object \n",
      " 19  customer_age_group      33164 non-null  int64  \n",
      " 20  payment_method          33164 non-null  object \n",
      " 21  delivery_days           33164 non-null  float64\n",
      " 22  delivery_type           33164 non-null  object \n",
      " 23  is_prime_member         33164 non-null  bool   \n",
      " 24  is_festival_sale        33164 non-null  bool   \n",
      " 25  festival_name           33164 non-null  object \n",
      " 26  customer_rating         33164 non-null  float64\n",
      " 27  return_status           33164 non-null  object \n",
      " 28  order_month             33164 non-null  int64  \n",
      " 29  order_year              33164 non-null  int64  \n",
      " 30  order_quarter           33164 non-null  int64  \n",
      " 31  product_weight_kg       33164 non-null  float64\n",
      " 32  is_prime_eligible       33164 non-null  bool   \n",
      " 33  product_rating          33164 non-null  float64\n",
      " 34  dup_key                 33164 non-null  object \n",
      " 35  dup_count               33164 non-null  int64  \n",
      " 36  dup_status              33000 non-null  object \n",
      " 37  flag_for_review         32999 non-null  object \n",
      "dtypes: bool(3), float64(10), int64(6), object(19)\n",
      "memory usage: 9.0+ MB\n",
      "‚úÖ Data Cleaning Completed & Saved Successfully: C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2015_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# üßπ Amazon India Data Cleaning\n",
    "# Author: Desikan\n",
    "# Project: Amazon India 10-Year Sales Analytics\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # hide pandas 3.0 warnings\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# ----------------------------------------\n",
    "file_path = r\"C:\\Users\\desik\\Downloads\\Amazon raw dataset\\amazon_india_2015.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"‚úÖ Dataset Loaded:\", df.shape)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3Ô∏è‚É£ Q1: Clean and Standardize Dates\n",
    "# ----------------------------------------\n",
    "def clean_date(date_input):\n",
    "    try:\n",
    "        parsed_date = parser.parse(str(date_input), dayfirst=True)\n",
    "        return parsed_date.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"order_date\"] = df[\"order_date\"].apply(clean_date)\n",
    "print(\"üóìÔ∏è Date column cleaned.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4Ô∏è‚É£ Q2: Clean and Standardize Price Columns (Improved Version)\n",
    "# ----------------------------------------\n",
    "import re\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_price(value):\n",
    "    try:\n",
    "        value = str(value).strip()\n",
    "        # Remove currency symbols and unwanted characters\n",
    "        value = re.sub(r'[‚ÇπRs√¢‚Äö¬π]', '', value, flags=re.IGNORECASE)\n",
    "        value = value.replace(',', '')\n",
    "        \n",
    "        # Handle text like 'Price on Request' or blanks\n",
    "        if not re.match(r'^-?\\d+(\\.\\d+)?$', value):\n",
    "            return pd.NA\n",
    "        \n",
    "        # Convert to float and make sure negatives are positive\n",
    "        return abs(float(value))\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply cleaning to all relevant columns\n",
    "price_cols = [\"original_price_inr\", \"discounted_price_inr\", \"final_amount_inr\", \"delivery_charges\"]\n",
    "\n",
    "for col in price_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_price)\n",
    "\n",
    "print(\"üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\")\n",
    "\n",
    "print(\"üí∞ Price columns cleaned and converted to numeric.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5Ô∏è‚É£ Q3: Standardize Ratings (1.0 - 5.0)\n",
    "# ----------------------------------------\n",
    "def clean_rating(value):\n",
    "    try:\n",
    "        val = str(value).lower().replace(\"stars\", \"\").replace(\"/5\", \"\").replace(\"/5.0\", \"\").strip()\n",
    "        return float(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].apply(clean_rating)\n",
    "df[\"product_rating\"] = df[\"product_rating\"].apply(clean_rating)\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].fillna(df[\"customer_rating\"].median())\n",
    "print(\"‚≠ê Ratings standardized to numeric scale.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6Ô∏è‚É£ Q4: Standardize City Names\n",
    "# ----------------------------------------\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype(str).str.title().str.strip()\n",
    "city_mapping = {\n",
    "    'ahmedabad': 'Ahmedabad',\n",
    "    'aligarh': 'Aligarh',\n",
    "    'allahabad': 'Allahabad',\n",
    "    'bangalore': 'Bengaluru',\n",
    "    'banglore': 'Bengaluru',\n",
    "    'bengalore': 'Bengaluru',\n",
    "    'bengaluru': 'Bengaluru',\n",
    "    'bhubaneswar': 'Bhubaneswar',\n",
    "    'bombay': 'Mumbai',\n",
    "    'calcutta': 'Kolkata',\n",
    "    'chandigarh': 'Chandigarh',\n",
    "    'chenai': 'Chennai',\n",
    "    'chennai': 'Chennai',\n",
    "    'coimbatore': 'Coimbatore',\n",
    "    'customer_city': 'Unknown',\n",
    "    'delhi': 'Delhi',\n",
    "    'delhi ncr': 'Delhi',\n",
    "    'new delhi': 'Delhi',\n",
    "    'gorakhpur': 'Gorakhpur',\n",
    "    'hyderabad': 'Hyderabad',\n",
    "    'indore': 'Indore',\n",
    "    'jaipur': 'Jaipur',\n",
    "    'kanpur': 'Kanpur',\n",
    "    'kochi': 'Kochi',\n",
    "    'kolkata': 'Kolkata',\n",
    "    'lucknow': 'Lucknow',\n",
    "    'ludhiana': 'Ludhiana',\n",
    "    'madras': 'Chennai',\n",
    "    'meerut': 'Meerut',\n",
    "    'moradabad': 'Moradabad',\n",
    "    'mumba': 'Mumbai',\n",
    "    'mumbai': 'Mumbai',\n",
    "    'nagpur': 'Nagpur',\n",
    "    'patna': 'Patna',\n",
    "    'pune': 'Pune',\n",
    "    'saharanpur': 'Saharanpur',\n",
    "    'surat': 'Surat',\n",
    "    'vadodara': 'Vadodara',\n",
    "    'varanasi': 'Varanasi',\n",
    "    'visakhapatnam': 'Visakhapatnam'\n",
    "}\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(city_mapping)\n",
    "print(\"üèôÔ∏è City names standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7Ô∏è‚É£ Q5: Clean Boolean Columns\n",
    "# ----------------------------------------\n",
    "bool_cols = [\"is_prime_member\", \"is_prime_eligible\", \"is_festival_sale\"]\n",
    "\n",
    "for col in bool_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .replace({\n",
    "            \"yes\": True, \"true\": True, \"1\": True, \"y\": True,\n",
    "            \"no\": False, \"false\": False, \"0\": False, \"n\": False\n",
    "        })\n",
    "    )\n",
    "    df[col] = df[col].astype(bool)\n",
    "\n",
    "print(\"üîò Boolean columns standardized to True/False.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 8Ô∏è‚É£ Q6: Standardize Product Categories\n",
    "# ----------------------------------------\n",
    "df[\"category\"] = df[\"category\"].astype(str).str.title().str.strip()\n",
    "category_mapping = {\n",
    "    'electronics': 'Electronics',\n",
    "    'electronic': 'Electronics',\n",
    "    'electronics & accessories': 'Electronics',\n",
    "    'electronicss': 'Electronics'\n",
    "}\n",
    "df[\"category\"] = df[\"category\"].replace(category_mapping)\n",
    "print(\"üõí Product categories standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 9Ô∏è‚É£ Q7: Clean Delivery Days\n",
    "# ----------------------------------------\n",
    "def clean_delivery_days(x):\n",
    "    x = str(x).lower()\n",
    "    if \"same\" in x:\n",
    "        return 0\n",
    "    elif \"-\" in x:\n",
    "        parts = x.replace(\"days\", \"\").split(\"-\")\n",
    "        parts = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(parts) if parts else np.nan\n",
    "    elif x.replace('.', '', 1).isdigit():\n",
    "        return float(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].apply(clean_delivery_days)\n",
    "df.loc[df[\"delivery_days\"] < 0, \"delivery_days\"] = np.nan\n",
    "df.loc[df[\"delivery_days\"] > 30, \"delivery_days\"] = np.nan\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].fillna(df[\"delivery_days\"].median())\n",
    "print(\"üöö Delivery days cleaned and standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# üîü Q8: Handle Duplicate Transactions\n",
    "# ----------------------------------------\n",
    "# Create composite key\n",
    "df['dup_key'] = df[['customer_id', 'product_id', 'order_date', 'final_amount_inr']].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# Count occurrences\n",
    "dup_counts = df['dup_key'].value_counts().to_dict()\n",
    "df['dup_count'] = df['dup_key'].map(dup_counts)\n",
    "\n",
    "def is_same_timestamp(group):\n",
    "    return group['order_date'].nunique() == 1\n",
    "\n",
    "def classify_group(group):\n",
    "    if group['dup_count'].iloc[0] > 3 and not is_same_timestamp(group):\n",
    "        return 'bulk_order'\n",
    "    elif is_same_timestamp(group) and group['dup_count'].iloc[0] > 1:\n",
    "        return 'error'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "df['dup_status'] = df.groupby('dup_key').apply(classify_group).reset_index(drop=True)\n",
    "\n",
    "def handle_duplicates(df):\n",
    "    cleaned = pd.DataFrame()\n",
    "    for key, group in df.groupby('dup_key'):\n",
    "        status = group['dup_status'].iloc[0]\n",
    "        if status == 'bulk_order':\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "        elif status == 'error':\n",
    "            cleaned = pd.concat([cleaned, group.head(1)])\n",
    "        elif status == 'uncertain':\n",
    "            group['flag_for_review'] = True\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "    return cleaned.reset_index(drop=True)\n",
    "\n",
    "df = handle_duplicates(df)\n",
    "print(\"üîÅ Smart duplicate handling applied (bulk, error, uncertain).\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Q9: Detect and Fix Outlier Prices (Optimized Version)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Step 1: Compute IQR bounds (fallback rule)\n",
    "Q1 = df['original_price_inr'].quantile(0.25)\n",
    "Q3 = df['original_price_inr'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "\n",
    "# Step 2: Define logical price ranges by subcategory\n",
    "subcategory_price_ranges = {\n",
    "    'smartphones': (5000, 100000),\n",
    "    'smart_watch': (500, 15000),\n",
    "    'audio': (300, 20000),\n",
    "    'tablets': (5000, 60000),\n",
    "    'laptops': (20000, 150000),\n",
    "    'tv_&_entertainment': (10000, 150000),\n",
    "    'home_appliances': (2000, 80000),\n",
    "    'accessories': (100, 10000)\n",
    "}\n",
    "\n",
    "# Step 3: Correction function\n",
    "def correct_price(row):\n",
    "    price = row['original_price_inr']\n",
    "    if pd.isna(price):\n",
    "        return price  # skip NaN\n",
    "    \n",
    "    subcat = str(row.get('subcategory', '')).strip().lower().replace(' ', '_')\n",
    "    expected = subcategory_price_ranges.get(subcat)\n",
    "    \n",
    "    # Rule 1: Subcategory-based correction\n",
    "    if expected:\n",
    "        min_p, max_p = expected\n",
    "        if price > max_p * 10:      # unusually high\n",
    "            return price / 100\n",
    "        elif price < min_p / 10:    # unusually low\n",
    "            return price * 100\n",
    "    \n",
    "    # Rule 2: Generic statistical correction\n",
    "    if price > upper_bound * 50:   # extreme high outlier (e.g., 100x mistake)\n",
    "        return price / 100\n",
    "    elif price < lower_bound / 50: # extreme low outlier\n",
    "        return price * 100\n",
    "    \n",
    "    return price\n",
    "\n",
    "# Step 4: Apply the correction efficiently\n",
    "df['original_price_inr'] = df.apply(correct_price, axis=1)\n",
    "\n",
    "print(\"üìà Outlier prices detected and corrected using statistical + category rules.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Q10: Standardize Payment Methods\n",
    "# ----------------------------------------\n",
    "df[\"payment_method\"] = df[\"payment_method\"].astype(str).str.lower().replace({\n",
    "    \"upi\": \"UPI\",\n",
    "    \"phonepe\": \"UPI\",\n",
    "    \"googlepay\": \"UPI\",\n",
    "    \"credit_card\": \"Credit Card\",\n",
    "    \"cc\": \"Credit Card\",\n",
    "    \"debit_card\": \"Debit Card\",\n",
    "    \"cod\": \"Cash On Delivery\",\n",
    "    \"c.o.d\": \"Cash On Delivery\"\n",
    "})\n",
    "print(\"üí≥ Payment methods standardized.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# üßÆ Handle Missing Values (Age, Festival, Delivery)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def convert_age_group(value):\n",
    "    \"\"\"\n",
    "    Convert age range formats like '18-25', '26-35', '55+' into numeric averages.\n",
    "    Handle blanks and unknowns as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"unknown\", \"na\", \"n/a\", \"none\", \"\", \"missing\"]:\n",
    "        return np.nan\n",
    "    if '-' in value:\n",
    "        parts = value.replace('years', '').split('-')\n",
    "        nums = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(nums) if nums else np.nan\n",
    "    if '+' in value:\n",
    "        num = value.replace('+', '').replace('years', '').strip()\n",
    "        if num.isdigit():\n",
    "            return float(num) + 5  # assume midpoint\n",
    "        return np.nan\n",
    "    if value.replace('.', '', 1).isdigit():\n",
    "        return float(value)\n",
    "    return np.nan\n",
    "\n",
    "# Apply to age column\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].apply(convert_age_group)\n",
    "avg_age = round(df[\"customer_age_group\"].mean())\n",
    "df[\"customer_age_group\"].fillna(avg_age, inplace=True)\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].astype(int)\n",
    "print(f\"üë§ Age column cleaned. Missing and unknown values filled with average: {avg_age}\")\n",
    "\n",
    "# Festival name fill\n",
    "df[\"festival_name\"].fillna(\"Unknown\", inplace=True)\n",
    "print(\"üéâ Festival names missing values filled with 'Unknown'.\")\n",
    "\n",
    "# Delivery charges fill\n",
    "df[\"delivery_charges\"].fillna(0, inplace=True)\n",
    "print(\"üí∞ Delivery charges missing values replaced with 0.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# ‚úÖ Final Checks & Save Cleaned Dataset\n",
    "# ----------------------------------------\n",
    "df.info()\n",
    "\n",
    "output_path = r\"C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2015_cleaned.csv\"\n",
    "\n",
    "# ‚úÖ Ensure output folder exists before saving\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "print(\"‚úÖ Data Cleaning Completed & Saved Successfully:\", output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b602f74",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970de9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded: (55275, 34)\n",
      "üóìÔ∏è Date column cleaned.\n",
      "üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\n",
      "üí∞ Price columns cleaned and converted to numeric.\n",
      "‚≠ê Ratings standardized to numeric scale.\n",
      "üèôÔ∏è City names standardized.\n",
      "üîò Boolean columns standardized to True/False.\n",
      "üõí Product categories standardized.\n",
      "üöö Delivery days cleaned and standardized.\n",
      "üîÅ Smart duplicate handling applied (bulk, error, uncertain).\n",
      "üìà Outlier prices detected and corrected using statistical + category rules.\n",
      "üí≥ Payment methods standardized.\n",
      "üë§ Age column cleaned. Missing and unknown values filled with average: 32\n",
      "üéâ Festival names missing values filled with 'Unknown'.\n",
      "üí∞ Delivery charges missing values replaced with 0.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55272 entries, 0 to 55271\n",
      "Data columns (total 38 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   transaction_id          55272 non-null  object \n",
      " 1   order_date              55272 non-null  object \n",
      " 2   customer_id             55272 non-null  object \n",
      " 3   product_id              55272 non-null  object \n",
      " 4   product_name            55272 non-null  object \n",
      " 5   category                55272 non-null  object \n",
      " 6   subcategory             55272 non-null  object \n",
      " 7   brand                   55272 non-null  object \n",
      " 8   original_price_inr      53637 non-null  object \n",
      " 9   discount_percent        55272 non-null  float64\n",
      " 10  discounted_price_inr    55272 non-null  float64\n",
      " 11  quantity                55272 non-null  int64  \n",
      " 12  subtotal_inr            55272 non-null  float64\n",
      " 13  delivery_charges        55272 non-null  float64\n",
      " 14  final_amount_inr        55272 non-null  float64\n",
      " 15  customer_city           55272 non-null  object \n",
      " 16  customer_state          55272 non-null  object \n",
      " 17  customer_tier           55272 non-null  object \n",
      " 18  customer_spending_tier  55272 non-null  object \n",
      " 19  customer_age_group      55272 non-null  int64  \n",
      " 20  payment_method          55272 non-null  object \n",
      " 21  delivery_days           55272 non-null  float64\n",
      " 22  delivery_type           55272 non-null  object \n",
      " 23  is_prime_member         55272 non-null  bool   \n",
      " 24  is_festival_sale        55272 non-null  bool   \n",
      " 25  festival_name           55272 non-null  object \n",
      " 26  customer_rating         55272 non-null  float64\n",
      " 27  return_status           55272 non-null  object \n",
      " 28  order_month             55272 non-null  int64  \n",
      " 29  order_year              55272 non-null  int64  \n",
      " 30  order_quarter           55272 non-null  int64  \n",
      " 31  product_weight_kg       55272 non-null  float64\n",
      " 32  is_prime_eligible       55272 non-null  bool   \n",
      " 33  product_rating          55272 non-null  float64\n",
      " 34  dup_key                 55272 non-null  object \n",
      " 35  dup_count               55272 non-null  int64  \n",
      " 36  dup_status              54999 non-null  object \n",
      " 37  flag_for_review         54996 non-null  object \n",
      "dtypes: bool(3), float64(9), int64(6), object(20)\n",
      "memory usage: 14.9+ MB\n",
      "‚úÖ Data Cleaning Completed & Saved Successfully: C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2016_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# üßπ Amazon India Data Cleaning \n",
    "# Author: Desikan\n",
    "# Project: Amazon India 10-Year Sales Analytics\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # hide pandas 3.0 warnings\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# ----------------------------------------\n",
    "file_path = r\"c:\\Users\\desik\\Downloads\\Amazon raw dataset\\amazon_india_2016.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"‚úÖ Dataset Loaded:\", df.shape)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3Ô∏è‚É£ Q1: Clean and Standardize Dates\n",
    "# ----------------------------------------\n",
    "def clean_date(date_input):\n",
    "    try:\n",
    "        parsed_date = parser.parse(str(date_input), dayfirst=True)\n",
    "        return parsed_date.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"order_date\"] = df[\"order_date\"].apply(clean_date)\n",
    "print(\"üóìÔ∏è Date column cleaned.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4Ô∏è‚É£ Q2: Clean and Standardize Price Columns (Improved Version)\n",
    "# ----------------------------------------\n",
    "import re\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_price(value):\n",
    "    try:\n",
    "        value = str(value).strip()\n",
    "        # Remove currency symbols and unwanted characters\n",
    "        value = re.sub(r'[‚ÇπRs√¢‚Äö¬π]', '', value, flags=re.IGNORECASE)\n",
    "        value = value.replace(',', '')\n",
    "        \n",
    "        # Handle text like 'Price on Request' or blanks\n",
    "        if not re.match(r'^-?\\d+(\\.\\d+)?$', value):\n",
    "            return pd.NA\n",
    "        \n",
    "        # Convert to float and make sure negatives are positive\n",
    "        return abs(float(value))\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply cleaning to all relevant columns\n",
    "price_cols = [\"original_price_inr\", \"discounted_price_inr\", \"final_amount_inr\", \"delivery_charges\"]\n",
    "\n",
    "for col in price_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_price)\n",
    "\n",
    "print(\"üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\")\n",
    "\n",
    "print(\"üí∞ Price columns cleaned and converted to numeric.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5Ô∏è‚É£ Q3: Standardize Ratings (1.0 - 5.0)\n",
    "# ----------------------------------------\n",
    "def clean_rating(value):\n",
    "    try:\n",
    "        val = str(value).lower().replace(\"stars\", \"\").replace(\"/5\", \"\").replace(\"/5.0\", \"\").strip()\n",
    "        return float(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].apply(clean_rating)\n",
    "df[\"product_rating\"] = df[\"product_rating\"].apply(clean_rating)\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].fillna(df[\"customer_rating\"].median())\n",
    "print(\"‚≠ê Ratings standardized to numeric scale.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6Ô∏è‚É£ Q4: Standardize City Names\n",
    "# ----------------------------------------\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype(str).str.title().str.strip()\n",
    "city_mapping = {\n",
    "    'ahmedabad': 'Ahmedabad',\n",
    "    'aligarh': 'Aligarh',\n",
    "    'allahabad': 'Allahabad',\n",
    "    'bangalore': 'Bengaluru',\n",
    "    'banglore': 'Bengaluru',\n",
    "    'bengalore': 'Bengaluru',\n",
    "    'bengaluru': 'Bengaluru',\n",
    "    'bhubaneswar': 'Bhubaneswar',\n",
    "    'bombay': 'Mumbai',\n",
    "    'calcutta': 'Kolkata',\n",
    "    'chandigarh': 'Chandigarh',\n",
    "    'chenai': 'Chennai',\n",
    "    'chennai': 'Chennai',\n",
    "    'coimbatore': 'Coimbatore',\n",
    "    'customer_city': 'Unknown',\n",
    "    'delhi': 'Delhi',\n",
    "    'delhi ncr': 'Delhi',\n",
    "    'new delhi': 'Delhi',\n",
    "    'gorakhpur': 'Gorakhpur',\n",
    "    'hyderabad': 'Hyderabad',\n",
    "    'indore': 'Indore',\n",
    "    'jaipur': 'Jaipur',\n",
    "    'kanpur': 'Kanpur',\n",
    "    'kochi': 'Kochi',\n",
    "    'kolkata': 'Kolkata',\n",
    "    'lucknow': 'Lucknow',\n",
    "    'ludhiana': 'Ludhiana',\n",
    "    'madras': 'Chennai',\n",
    "    'meerut': 'Meerut',\n",
    "    'moradabad': 'Moradabad',\n",
    "    'mumba': 'Mumbai',\n",
    "    'mumbai': 'Mumbai',\n",
    "    'nagpur': 'Nagpur',\n",
    "    'patna': 'Patna',\n",
    "    'pune': 'Pune',\n",
    "    'saharanpur': 'Saharanpur',\n",
    "    'surat': 'Surat',\n",
    "    'vadodara': 'Vadodara',\n",
    "    'varanasi': 'Varanasi',\n",
    "    'visakhapatnam': 'Visakhapatnam'\n",
    "}\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(city_mapping)\n",
    "print(\"üèôÔ∏è City names standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7Ô∏è‚É£ Q5: Clean Boolean Columns\n",
    "# ----------------------------------------\n",
    "bool_cols = [\"is_prime_member\", \"is_prime_eligible\", \"is_festival_sale\"]\n",
    "\n",
    "for col in bool_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .replace({\n",
    "            \"yes\": True, \"true\": True, \"1\": True, \"y\": True,\n",
    "            \"no\": False, \"false\": False, \"0\": False, \"n\": False\n",
    "        })\n",
    "    )\n",
    "    df[col] = df[col].astype(bool)\n",
    "\n",
    "print(\"üîò Boolean columns standardized to True/False.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 8Ô∏è‚É£ Q6: Standardize Product Categories\n",
    "# ----------------------------------------\n",
    "df[\"category\"] = df[\"category\"].astype(str).str.title().str.strip()\n",
    "category_mapping = {\n",
    "    'electronics': 'Electronics',\n",
    "    'electronic': 'Electronics',\n",
    "    'electronics & accessories': 'Electronics',\n",
    "    'electronicss': 'Electronics'\n",
    "}\n",
    "df[\"category\"] = df[\"category\"].replace(category_mapping)\n",
    "print(\"üõí Product categories standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 9Ô∏è‚É£ Q7: Clean Delivery Days\n",
    "# ----------------------------------------\n",
    "def clean_delivery_days(x):\n",
    "    x = str(x).lower()\n",
    "    if \"same\" in x:\n",
    "        return 0\n",
    "    elif \"-\" in x:\n",
    "        parts = x.replace(\"days\", \"\").split(\"-\")\n",
    "        parts = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(parts) if parts else np.nan\n",
    "    elif x.replace('.', '', 1).isdigit():\n",
    "        return float(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].apply(clean_delivery_days)\n",
    "df.loc[df[\"delivery_days\"] < 0, \"delivery_days\"] = np.nan\n",
    "df.loc[df[\"delivery_days\"] > 30, \"delivery_days\"] = np.nan\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].fillna(df[\"delivery_days\"].median())\n",
    "print(\"üöö Delivery days cleaned and standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# üîü Q8: Handle Duplicate Transactions\n",
    "# ----------------------------------------\n",
    "# Create composite key\n",
    "df['dup_key'] = df[['customer_id', 'product_id', 'order_date', 'final_amount_inr']].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# Count occurrences\n",
    "dup_counts = df['dup_key'].value_counts().to_dict()\n",
    "df['dup_count'] = df['dup_key'].map(dup_counts)\n",
    "\n",
    "def is_same_timestamp(group):\n",
    "    return group['order_date'].nunique() == 1\n",
    "\n",
    "def classify_group(group):\n",
    "    if group['dup_count'].iloc[0] > 3 and not is_same_timestamp(group):\n",
    "        return 'bulk_order'\n",
    "    elif is_same_timestamp(group) and group['dup_count'].iloc[0] > 1:\n",
    "        return 'error'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "df['dup_status'] = df.groupby('dup_key').apply(classify_group).reset_index(drop=True)\n",
    "\n",
    "def handle_duplicates(df):\n",
    "    cleaned = pd.DataFrame()\n",
    "    for key, group in df.groupby('dup_key'):\n",
    "        status = group['dup_status'].iloc[0]\n",
    "        if status == 'bulk_order':\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "        elif status == 'error':\n",
    "            cleaned = pd.concat([cleaned, group.head(1)])\n",
    "        elif status == 'uncertain':\n",
    "            group['flag_for_review'] = True\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "    return cleaned.reset_index(drop=True)\n",
    "\n",
    "df = handle_duplicates(df)\n",
    "print(\"üîÅ Smart duplicate handling applied (bulk, error, uncertain).\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Q9: Detect and Fix Outlier Prices (Optimized Version)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Step 1: Compute IQR bounds (fallback rule)\n",
    "Q1 = df['original_price_inr'].quantile(0.25)\n",
    "Q3 = df['original_price_inr'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "\n",
    "# Step 2: Define logical price ranges by subcategory\n",
    "subcategory_price_ranges = {\n",
    "    'smartphones': (5000, 100000),\n",
    "    'smart_watch': (500, 15000),\n",
    "    'audio': (300, 20000),\n",
    "    'tablets': (5000, 60000),\n",
    "    'laptops': (20000, 150000),\n",
    "    'tv_&_entertainment': (10000, 150000),\n",
    "    'home_appliances': (2000, 80000),\n",
    "    'accessories': (100, 10000)\n",
    "}\n",
    "\n",
    "# Step 3: Correction function\n",
    "def correct_price(row):\n",
    "    price = row['original_price_inr']\n",
    "    if pd.isna(price):\n",
    "        return price  # skip NaN\n",
    "    \n",
    "    subcat = str(row.get('subcategory', '')).strip().lower().replace(' ', '_')\n",
    "    expected = subcategory_price_ranges.get(subcat)\n",
    "    \n",
    "    # Rule 1: Subcategory-based correction\n",
    "    if expected:\n",
    "        min_p, max_p = expected\n",
    "        if price > max_p * 10:      # unusually high\n",
    "            return price / 100\n",
    "        elif price < min_p / 10:    # unusually low\n",
    "            return price * 100\n",
    "    \n",
    "    # Rule 2: Generic statistical correction\n",
    "    if price > upper_bound * 50:   # extreme high outlier (e.g., 100x mistake)\n",
    "        return price / 100\n",
    "    elif price < lower_bound / 50: # extreme low outlier\n",
    "        return price * 100\n",
    "    \n",
    "    return price\n",
    "\n",
    "# Step 4: Apply the correction efficiently\n",
    "df['original_price_inr'] = df.apply(correct_price, axis=1)\n",
    "\n",
    "print(\"üìà Outlier prices detected and corrected using statistical + category rules.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Q10: Standardize Payment Methods\n",
    "# ----------------------------------------\n",
    "df[\"payment_method\"] = df[\"payment_method\"].astype(str).str.lower().replace({\n",
    "    \"upi\": \"UPI\",\n",
    "    \"phonepe\": \"UPI\",\n",
    "    \"googlepay\": \"UPI\",\n",
    "    \"credit_card\": \"Credit Card\",\n",
    "    \"cc\": \"Credit Card\",\n",
    "    \"debit_card\": \"Debit Card\",\n",
    "    \"cod\": \"Cash On Delivery\",\n",
    "    \"c.o.d\": \"Cash On Delivery\"\n",
    "})\n",
    "print(\"üí≥ Payment methods standardized.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# üßÆ Handle Missing Values (Age, Festival, Delivery)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def convert_age_group(value):\n",
    "    \"\"\"\n",
    "    Convert age range formats like '18-25', '26-35', '55+' into numeric averages.\n",
    "    Handle blanks and unknowns as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"unknown\", \"na\", \"n/a\", \"none\", \"\", \"missing\"]:\n",
    "        return np.nan\n",
    "    if '-' in value:\n",
    "        parts = value.replace('years', '').split('-')\n",
    "        nums = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(nums) if nums else np.nan\n",
    "    if '+' in value:\n",
    "        num = value.replace('+', '').replace('years', '').strip()\n",
    "        if num.isdigit():\n",
    "            return float(num) + 5  # assume midpoint\n",
    "        return np.nan\n",
    "    if value.replace('.', '', 1).isdigit():\n",
    "        return float(value)\n",
    "    return np.nan\n",
    "\n",
    "# Apply to age column\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].apply(convert_age_group)\n",
    "avg_age = round(df[\"customer_age_group\"].mean())\n",
    "df[\"customer_age_group\"].fillna(avg_age, inplace=True)\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].astype(int)\n",
    "print(f\"üë§ Age column cleaned. Missing and unknown values filled with average: {avg_age}\")\n",
    "\n",
    "# Festival name fill\n",
    "df[\"festival_name\"].fillna(\"Unknown\", inplace=True)\n",
    "print(\"üéâ Festival names missing values filled with 'Unknown'.\")\n",
    "\n",
    "# Delivery charges fill\n",
    "df[\"delivery_charges\"].fillna(0, inplace=True)\n",
    "print(\"üí∞ Delivery charges missing values replaced with 0.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# ‚úÖ Final Checks & Save Cleaned Dataset\n",
    "# ----------------------------------------\n",
    "df.info()\n",
    "\n",
    "output_path = r\"C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2016_cleaned.csv\"\n",
    "\n",
    "# ‚úÖ Ensure output folder exists before saving\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "print(\"‚úÖ Data Cleaning Completed & Saved Successfully:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41bbd7",
   "metadata": {},
   "source": [
    "### 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7690a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded: (77385, 34)\n",
      "üóìÔ∏è Date column cleaned.\n",
      "üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\n",
      "üí∞ Price columns cleaned and converted to numeric.\n",
      "‚≠ê Ratings standardized to numeric scale.\n",
      "üèôÔ∏è City names standardized.\n",
      "üîò Boolean columns standardized to True/False.\n",
      "üõí Product categories standardized.\n",
      "üöö Delivery days cleaned and standardized.\n",
      "üîÅ Smart duplicate handling applied (bulk, error, uncertain).\n",
      "üìà Outlier prices detected and corrected using statistical + category rules.\n",
      "üí≥ Payment methods standardized.\n",
      "üë§ Age column cleaned. Missing and unknown values filled with average: 33\n",
      "üéâ Festival names missing values filled with 'Unknown'.\n",
      "üí∞ Delivery charges missing values replaced with 0.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77382 entries, 0 to 77381\n",
      "Data columns (total 38 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   transaction_id          77382 non-null  object \n",
      " 1   order_date              77382 non-null  object \n",
      " 2   customer_id             77382 non-null  object \n",
      " 3   product_id              77382 non-null  object \n",
      " 4   product_name            77382 non-null  object \n",
      " 5   category                77382 non-null  object \n",
      " 6   subcategory             77382 non-null  object \n",
      " 7   brand                   77382 non-null  object \n",
      " 8   original_price_inr      75103 non-null  float64\n",
      " 9   discount_percent        77382 non-null  float64\n",
      " 10  discounted_price_inr    77382 non-null  float64\n",
      " 11  quantity                77382 non-null  int64  \n",
      " 12  subtotal_inr            77382 non-null  float64\n",
      " 13  delivery_charges        77382 non-null  float64\n",
      " 14  final_amount_inr        77382 non-null  float64\n",
      " 15  customer_city           77382 non-null  object \n",
      " 16  customer_state          77382 non-null  object \n",
      " 17  customer_tier           77382 non-null  object \n",
      " 18  customer_spending_tier  77382 non-null  object \n",
      " 19  customer_age_group      77382 non-null  int64  \n",
      " 20  payment_method          77382 non-null  object \n",
      " 21  delivery_days           77382 non-null  float64\n",
      " 22  delivery_type           77382 non-null  object \n",
      " 23  is_prime_member         77382 non-null  bool   \n",
      " 24  is_festival_sale        77382 non-null  bool   \n",
      " 25  festival_name           77382 non-null  object \n",
      " 26  customer_rating         77382 non-null  float64\n",
      " 27  return_status           77382 non-null  object \n",
      " 28  order_month             77382 non-null  int64  \n",
      " 29  order_year              77382 non-null  int64  \n",
      " 30  order_quarter           77382 non-null  int64  \n",
      " 31  product_weight_kg       77382 non-null  float64\n",
      " 32  is_prime_eligible       77382 non-null  bool   \n",
      " 33  product_rating          77382 non-null  float64\n",
      " 34  dup_key                 77382 non-null  object \n",
      " 35  dup_count               77382 non-null  int64  \n",
      " 36  dup_status              77000 non-null  object \n",
      " 37  flag_for_review         76997 non-null  object \n",
      "dtypes: bool(3), float64(10), int64(6), object(19)\n",
      "memory usage: 20.9+ MB\n",
      "‚úÖ Data Cleaning Completed & Saved Successfully: C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2017_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# üßπ Amazon India Data Cleaning \n",
    "# Author: Desikan\n",
    "# Project: Amazon India 10-Year Sales Analytics\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # hide pandas 3.0 warnings\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# ----------------------------------------\n",
    "file_path = r\"C:\\Users\\desik\\Downloads\\Amazon raw dataset\\amazon_india_2017.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"‚úÖ Dataset Loaded:\", df.shape)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3Ô∏è‚É£ Q1: Clean and Standardize Dates\n",
    "# ----------------------------------------\n",
    "def clean_date(date_input):\n",
    "    try:\n",
    "        parsed_date = parser.parse(str(date_input), dayfirst=True)\n",
    "        return parsed_date.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"order_date\"] = df[\"order_date\"].apply(clean_date)\n",
    "print(\"üóìÔ∏è Date column cleaned.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4Ô∏è‚É£ Q2: Clean and Standardize Price Columns (Improved Version)\n",
    "# ----------------------------------------\n",
    "import re\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_price(value):\n",
    "    try:\n",
    "        value = str(value).strip()\n",
    "        # Remove currency symbols and unwanted characters\n",
    "        value = re.sub(r'[‚ÇπRs√¢‚Äö¬π]', '', value, flags=re.IGNORECASE)\n",
    "        value = value.replace(',', '')\n",
    "        \n",
    "        # Handle text like 'Price on Request' or blanks\n",
    "        if not re.match(r'^-?\\d+(\\.\\d+)?$', value):\n",
    "            return pd.NA\n",
    "        \n",
    "        # Convert to float and make sure negatives are positive\n",
    "        return abs(float(value))\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply cleaning to all relevant columns\n",
    "price_cols = [\"original_price_inr\", \"discounted_price_inr\", \"final_amount_inr\", \"delivery_charges\"]\n",
    "\n",
    "for col in price_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_price)\n",
    "\n",
    "print(\"üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\")\n",
    "\n",
    "print(\"üí∞ Price columns cleaned and converted to numeric.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5Ô∏è‚É£ Q3: Standardize Ratings (1.0 - 5.0)\n",
    "# ----------------------------------------\n",
    "def clean_rating(value):\n",
    "    try:\n",
    "        val = str(value).lower().replace(\"stars\", \"\").replace(\"/5\", \"\").replace(\"/5.0\", \"\").strip()\n",
    "        return float(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].apply(clean_rating)\n",
    "df[\"product_rating\"] = df[\"product_rating\"].apply(clean_rating)\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].fillna(df[\"customer_rating\"].median())\n",
    "print(\"‚≠ê Ratings standardized to numeric scale.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6Ô∏è‚É£ Q4: Standardize City Names\n",
    "# ----------------------------------------\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype(str).str.title().str.strip()\n",
    "city_mapping = {\n",
    "    'ahmedabad': 'Ahmedabad',\n",
    "    'aligarh': 'Aligarh',\n",
    "    'allahabad': 'Allahabad',\n",
    "    'bangalore': 'Bengaluru',\n",
    "    'banglore': 'Bengaluru',\n",
    "    'bengalore': 'Bengaluru',\n",
    "    'bengaluru': 'Bengaluru',\n",
    "    'bhubaneswar': 'Bhubaneswar',\n",
    "    'bombay': 'Mumbai',\n",
    "    'calcutta': 'Kolkata',\n",
    "    'chandigarh': 'Chandigarh',\n",
    "    'chenai': 'Chennai',\n",
    "    'chennai': 'Chennai',\n",
    "    'coimbatore': 'Coimbatore',\n",
    "    'customer_city': 'Unknown',\n",
    "    'delhi': 'Delhi',\n",
    "    'delhi ncr': 'Delhi',\n",
    "    'new delhi': 'Delhi',\n",
    "    'gorakhpur': 'Gorakhpur',\n",
    "    'hyderabad': 'Hyderabad',\n",
    "    'indore': 'Indore',\n",
    "    'jaipur': 'Jaipur',\n",
    "    'kanpur': 'Kanpur',\n",
    "    'kochi': 'Kochi',\n",
    "    'kolkata': 'Kolkata',\n",
    "    'lucknow': 'Lucknow',\n",
    "    'ludhiana': 'Ludhiana',\n",
    "    'madras': 'Chennai',\n",
    "    'meerut': 'Meerut',\n",
    "    'moradabad': 'Moradabad',\n",
    "    'mumba': 'Mumbai',\n",
    "    'mumbai': 'Mumbai',\n",
    "    'nagpur': 'Nagpur',\n",
    "    'patna': 'Patna',\n",
    "    'pune': 'Pune',\n",
    "    'saharanpur': 'Saharanpur',\n",
    "    'surat': 'Surat',\n",
    "    'vadodara': 'Vadodara',\n",
    "    'varanasi': 'Varanasi',\n",
    "    'visakhapatnam': 'Visakhapatnam'\n",
    "}\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(city_mapping)\n",
    "print(\"üèôÔ∏è City names standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7Ô∏è‚É£ Q5: Clean Boolean Columns\n",
    "# ----------------------------------------\n",
    "bool_cols = [\"is_prime_member\", \"is_prime_eligible\", \"is_festival_sale\"]\n",
    "\n",
    "for col in bool_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .replace({\n",
    "            \"yes\": True, \"true\": True, \"1\": True, \"y\": True,\n",
    "            \"no\": False, \"false\": False, \"0\": False, \"n\": False\n",
    "        })\n",
    "    )\n",
    "    df[col] = df[col].astype(bool)\n",
    "\n",
    "print(\"üîò Boolean columns standardized to True/False.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 8Ô∏è‚É£ Q6: Standardize Product Categories\n",
    "# ----------------------------------------\n",
    "df[\"category\"] = df[\"category\"].astype(str).str.title().str.strip()\n",
    "category_mapping = {\n",
    "    'electronics': 'Electronics',\n",
    "    'electronic': 'Electronics',\n",
    "    'electronics & accessories': 'Electronics',\n",
    "    'electronicss': 'Electronics'\n",
    "}\n",
    "df[\"category\"] = df[\"category\"].replace(category_mapping)\n",
    "print(\"üõí Product categories standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 9Ô∏è‚É£ Q7: Clean Delivery Days\n",
    "# ----------------------------------------\n",
    "def clean_delivery_days(x):\n",
    "    x = str(x).lower()\n",
    "    if \"same\" in x:\n",
    "        return 0\n",
    "    elif \"-\" in x:\n",
    "        parts = x.replace(\"days\", \"\").split(\"-\")\n",
    "        parts = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(parts) if parts else np.nan\n",
    "    elif x.replace('.', '', 1).isdigit():\n",
    "        return float(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].apply(clean_delivery_days)\n",
    "df.loc[df[\"delivery_days\"] < 0, \"delivery_days\"] = np.nan\n",
    "df.loc[df[\"delivery_days\"] > 30, \"delivery_days\"] = np.nan\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].fillna(df[\"delivery_days\"].median())\n",
    "print(\"üöö Delivery days cleaned and standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# üîü Q8: Handle Duplicate Transactions\n",
    "# ----------------------------------------\n",
    "# Create composite key\n",
    "df['dup_key'] = df[['customer_id', 'product_id', 'order_date', 'final_amount_inr']].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# Count occurrences\n",
    "dup_counts = df['dup_key'].value_counts().to_dict()\n",
    "df['dup_count'] = df['dup_key'].map(dup_counts)\n",
    "\n",
    "def is_same_timestamp(group):\n",
    "    return group['order_date'].nunique() == 1\n",
    "\n",
    "def classify_group(group):\n",
    "    if group['dup_count'].iloc[0] > 3 and not is_same_timestamp(group):\n",
    "        return 'bulk_order'\n",
    "    elif is_same_timestamp(group) and group['dup_count'].iloc[0] > 1:\n",
    "        return 'error'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "df['dup_status'] = df.groupby('dup_key').apply(classify_group).reset_index(drop=True)\n",
    "\n",
    "def handle_duplicates(df):\n",
    "    cleaned = pd.DataFrame()\n",
    "    for key, group in df.groupby('dup_key'):\n",
    "        status = group['dup_status'].iloc[0]\n",
    "        if status == 'bulk_order':\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "        elif status == 'error':\n",
    "            cleaned = pd.concat([cleaned, group.head(1)])\n",
    "        elif status == 'uncertain':\n",
    "            group['flag_for_review'] = True\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "    return cleaned.reset_index(drop=True)\n",
    "\n",
    "df = handle_duplicates(df)\n",
    "print(\"üîÅ Smart duplicate handling applied (bulk, error, uncertain).\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Q9: Detect and Fix Outlier Prices (Optimized Version)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Step 1: Compute IQR bounds (fallback rule)\n",
    "Q1 = df['original_price_inr'].quantile(0.25)\n",
    "Q3 = df['original_price_inr'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "\n",
    "# Step 2: Define logical price ranges by subcategory\n",
    "subcategory_price_ranges = {\n",
    "    'smartphones': (5000, 100000),\n",
    "    'smart_watch': (500, 15000),\n",
    "    'audio': (300, 20000),\n",
    "    'tablets': (5000, 60000),\n",
    "    'laptops': (20000, 150000),\n",
    "    'tv_&_entertainment': (10000, 150000),\n",
    "    'home_appliances': (2000, 80000),\n",
    "    'accessories': (100, 10000)\n",
    "}\n",
    "\n",
    "# Step 3: Correction function\n",
    "def correct_price(row):\n",
    "    price = row['original_price_inr']\n",
    "    if pd.isna(price):\n",
    "        return price  # skip NaN\n",
    "    \n",
    "    subcat = str(row.get('subcategory', '')).strip().lower().replace(' ', '_')\n",
    "    expected = subcategory_price_ranges.get(subcat)\n",
    "    \n",
    "    # Rule 1: Subcategory-based correction\n",
    "    if expected:\n",
    "        min_p, max_p = expected\n",
    "        if price > max_p * 10:      # unusually high\n",
    "            return price / 100\n",
    "        elif price < min_p / 10:    # unusually low\n",
    "            return price * 100\n",
    "    \n",
    "    # Rule 2: Generic statistical correction\n",
    "    if price > upper_bound * 50:   # extreme high outlier (e.g., 100x mistake)\n",
    "        return price / 100\n",
    "    elif price < lower_bound / 50: # extreme low outlier\n",
    "        return price * 100\n",
    "    \n",
    "    return price\n",
    "\n",
    "# Step 4: Apply the correction efficiently\n",
    "df['original_price_inr'] = df.apply(correct_price, axis=1)\n",
    "\n",
    "print(\"üìà Outlier prices detected and corrected using statistical + category rules.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Q10: Standardize Payment Methods\n",
    "# ----------------------------------------\n",
    "df[\"payment_method\"] = df[\"payment_method\"].astype(str).str.lower().replace({\n",
    "    \"upi\": \"UPI\",\n",
    "    \"phonepe\": \"UPI\",\n",
    "    \"googlepay\": \"UPI\",\n",
    "    \"credit_card\": \"Credit Card\",\n",
    "    \"cc\": \"Credit Card\",\n",
    "    \"debit_card\": \"Debit Card\",\n",
    "    \"cod\": \"Cash On Delivery\",\n",
    "    \"c.o.d\": \"Cash On Delivery\"\n",
    "})\n",
    "print(\"üí≥ Payment methods standardized.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# üßÆ Handle Missing Values (Age, Festival, Delivery)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def convert_age_group(value):\n",
    "    \"\"\"\n",
    "    Convert age range formats like '18-25', '26-35', '55+' into numeric averages.\n",
    "    Handle blanks and unknowns as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"unknown\", \"na\", \"n/a\", \"none\", \"\", \"missing\"]:\n",
    "        return np.nan\n",
    "    if '-' in value:\n",
    "        parts = value.replace('years', '').split('-')\n",
    "        nums = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(nums) if nums else np.nan\n",
    "    if '+' in value:\n",
    "        num = value.replace('+', '').replace('years', '').strip()\n",
    "        if num.isdigit():\n",
    "            return float(num) + 5  # assume midpoint\n",
    "        return np.nan\n",
    "    if value.replace('.', '', 1).isdigit():\n",
    "        return float(value)\n",
    "    return np.nan\n",
    "\n",
    "# Apply to age column\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].apply(convert_age_group)\n",
    "avg_age = round(df[\"customer_age_group\"].mean())\n",
    "df[\"customer_age_group\"].fillna(avg_age, inplace=True)\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].astype(int)\n",
    "print(f\"üë§ Age column cleaned. Missing and unknown values filled with average: {avg_age}\")\n",
    "\n",
    "# Festival name fill\n",
    "df[\"festival_name\"].fillna(\"Unknown\", inplace=True)\n",
    "print(\"üéâ Festival names missing values filled with 'Unknown'.\")\n",
    "\n",
    "# Delivery charges fill\n",
    "df[\"delivery_charges\"].fillna(0, inplace=True)\n",
    "print(\"üí∞ Delivery charges missing values replaced with 0.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# ‚úÖ Final Checks & Save Cleaned Dataset\n",
    "# ----------------------------------------\n",
    "df.info()\n",
    "\n",
    "output_path = r\"C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2017_cleaned.csv\"\n",
    "\n",
    "# ‚úÖ Ensure output folder exists before saving\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "print(\"‚úÖ Data Cleaning Completed & Saved Successfully:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bde6b86",
   "metadata": {},
   "source": [
    "### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d26f8db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded: (99495, 34)\n",
      "üóìÔ∏è Date column cleaned.\n",
      "üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\n",
      "üí∞ Price columns cleaned and converted to numeric.\n",
      "‚≠ê Ratings standardized to numeric scale.\n",
      "üèôÔ∏è City names standardized.\n",
      "üîò Boolean columns standardized to True/False.\n",
      "üõí Product categories standardized.\n",
      "üöö Delivery days cleaned and standardized.\n",
      "üîÅ Smart duplicate handling applied (bulk, error, uncertain).\n",
      "üìà Outlier prices detected and corrected using statistical + category rules.\n",
      "üí≥ Payment methods standardized.\n",
      "üë§ Age column cleaned. Missing and unknown values filled with average: 32\n",
      "üéâ Festival names missing values filled with 'Unknown'.\n",
      "üí∞ Delivery charges missing values replaced with 0.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99488 entries, 0 to 99487\n",
      "Data columns (total 38 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   transaction_id          99488 non-null  object \n",
      " 1   order_date              99488 non-null  object \n",
      " 2   customer_id             99488 non-null  object \n",
      " 3   product_id              99488 non-null  object \n",
      " 4   product_name            99488 non-null  object \n",
      " 5   category                99488 non-null  object \n",
      " 6   subcategory             99488 non-null  object \n",
      " 7   brand                   99488 non-null  object \n",
      " 8   original_price_inr      96506 non-null  float64\n",
      " 9   discount_percent        99488 non-null  float64\n",
      " 10  discounted_price_inr    99488 non-null  float64\n",
      " 11  quantity                99488 non-null  int64  \n",
      " 12  subtotal_inr            99488 non-null  float64\n",
      " 13  delivery_charges        99488 non-null  float64\n",
      " 14  final_amount_inr        99488 non-null  float64\n",
      " 15  customer_city           99488 non-null  object \n",
      " 16  customer_state          99488 non-null  object \n",
      " 17  customer_tier           99488 non-null  object \n",
      " 18  customer_spending_tier  99488 non-null  object \n",
      " 19  customer_age_group      99488 non-null  int64  \n",
      " 20  payment_method          99488 non-null  object \n",
      " 21  delivery_days           99488 non-null  float64\n",
      " 22  delivery_type           99488 non-null  object \n",
      " 23  is_prime_member         99488 non-null  bool   \n",
      " 24  is_festival_sale        99488 non-null  bool   \n",
      " 25  festival_name           99488 non-null  object \n",
      " 26  customer_rating         99488 non-null  float64\n",
      " 27  return_status           99488 non-null  object \n",
      " 28  order_month             99488 non-null  int64  \n",
      " 29  order_year              99488 non-null  int64  \n",
      " 30  order_quarter           99488 non-null  int64  \n",
      " 31  product_weight_kg       99488 non-null  float64\n",
      " 32  is_prime_eligible       99488 non-null  bool   \n",
      " 33  product_rating          99488 non-null  float64\n",
      " 34  dup_key                 99488 non-null  object \n",
      " 35  dup_count               99488 non-null  int64  \n",
      " 36  dup_status              99000 non-null  object \n",
      " 37  flag_for_review         98993 non-null  object \n",
      "dtypes: bool(3), float64(10), int64(6), object(19)\n",
      "memory usage: 26.9+ MB\n",
      "‚úÖ Data Cleaning Completed & Saved Successfully: C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2018_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# üßπ Amazon India Data Cleaning \n",
    "# Author: Desikan\n",
    "# Project: Amazon India 10-Year Sales Analytics\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # hide pandas 3.0 warnings\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# ----------------------------------------\n",
    "file_path = r\"C:\\Users\\desik\\Downloads\\Amazon raw dataset\\amazon_india_2018.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"‚úÖ Dataset Loaded:\", df.shape)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3Ô∏è‚É£ Q1: Clean and Standardize Dates\n",
    "# ----------------------------------------\n",
    "def clean_date(date_input):\n",
    "    try:\n",
    "        parsed_date = parser.parse(str(date_input), dayfirst=True)\n",
    "        return parsed_date.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"order_date\"] = df[\"order_date\"].apply(clean_date)\n",
    "print(\"üóìÔ∏è Date column cleaned.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4Ô∏è‚É£ Q2: Clean and Standardize Price Columns (Improved Version)\n",
    "# ----------------------------------------\n",
    "import re\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_price(value):\n",
    "    try:\n",
    "        value = str(value).strip()\n",
    "        # Remove currency symbols and unwanted characters\n",
    "        value = re.sub(r'[‚ÇπRs√¢‚Äö¬π]', '', value, flags=re.IGNORECASE)\n",
    "        value = value.replace(',', '')\n",
    "        \n",
    "        # Handle text like 'Price on Request' or blanks\n",
    "        if not re.match(r'^-?\\d+(\\.\\d+)?$', value):\n",
    "            return pd.NA\n",
    "        \n",
    "        # Convert to float and make sure negatives are positive\n",
    "        return abs(float(value))\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply cleaning to all relevant columns\n",
    "price_cols = [\"original_price_inr\", \"discounted_price_inr\", \"final_amount_inr\", \"delivery_charges\"]\n",
    "\n",
    "for col in price_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_price)\n",
    "\n",
    "print(\"üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\")\n",
    "\n",
    "print(\"üí∞ Price columns cleaned and converted to numeric.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5Ô∏è‚É£ Q3: Standardize Ratings (1.0 - 5.0)\n",
    "# ----------------------------------------\n",
    "def clean_rating(value):\n",
    "    try:\n",
    "        val = str(value).lower().replace(\"stars\", \"\").replace(\"/5\", \"\").replace(\"/5.0\", \"\").strip()\n",
    "        return float(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].apply(clean_rating)\n",
    "df[\"product_rating\"] = df[\"product_rating\"].apply(clean_rating)\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].fillna(df[\"customer_rating\"].median())\n",
    "print(\"‚≠ê Ratings standardized to numeric scale.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6Ô∏è‚É£ Q4: Standardize City Names\n",
    "# ----------------------------------------\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype(str).str.title().str.strip()\n",
    "city_mapping = {\n",
    "    'ahmedabad': 'Ahmedabad',\n",
    "    'aligarh': 'Aligarh',\n",
    "    'allahabad': 'Allahabad',\n",
    "    'bangalore': 'Bengaluru',\n",
    "    'banglore': 'Bengaluru',\n",
    "    'bengalore': 'Bengaluru',\n",
    "    'bengaluru': 'Bengaluru',\n",
    "    'bhubaneswar': 'Bhubaneswar',\n",
    "    'bombay': 'Mumbai',\n",
    "    'calcutta': 'Kolkata',\n",
    "    'chandigarh': 'Chandigarh',\n",
    "    'chenai': 'Chennai',\n",
    "    'chennai': 'Chennai',\n",
    "    'coimbatore': 'Coimbatore',\n",
    "    'customer_city': 'Unknown',\n",
    "    'delhi': 'Delhi',\n",
    "    'delhi ncr': 'Delhi',\n",
    "    'new delhi': 'Delhi',\n",
    "    'gorakhpur': 'Gorakhpur',\n",
    "    'hyderabad': 'Hyderabad',\n",
    "    'indore': 'Indore',\n",
    "    'jaipur': 'Jaipur',\n",
    "    'kanpur': 'Kanpur',\n",
    "    'kochi': 'Kochi',\n",
    "    'kolkata': 'Kolkata',\n",
    "    'lucknow': 'Lucknow',\n",
    "    'ludhiana': 'Ludhiana',\n",
    "    'madras': 'Chennai',\n",
    "    'meerut': 'Meerut',\n",
    "    'moradabad': 'Moradabad',\n",
    "    'mumba': 'Mumbai',\n",
    "    'mumbai': 'Mumbai',\n",
    "    'nagpur': 'Nagpur',\n",
    "    'patna': 'Patna',\n",
    "    'pune': 'Pune',\n",
    "    'saharanpur': 'Saharanpur',\n",
    "    'surat': 'Surat',\n",
    "    'vadodara': 'Vadodara',\n",
    "    'varanasi': 'Varanasi',\n",
    "    'visakhapatnam': 'Visakhapatnam'\n",
    "}\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(city_mapping)\n",
    "print(\"üèôÔ∏è City names standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7Ô∏è‚É£ Q5: Clean Boolean Columns\n",
    "# ----------------------------------------\n",
    "bool_cols = [\"is_prime_member\", \"is_prime_eligible\", \"is_festival_sale\"]\n",
    "\n",
    "for col in bool_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .replace({\n",
    "            \"yes\": True, \"true\": True, \"1\": True, \"y\": True,\n",
    "            \"no\": False, \"false\": False, \"0\": False, \"n\": False\n",
    "        })\n",
    "    )\n",
    "    df[col] = df[col].astype(bool)\n",
    "\n",
    "print(\"üîò Boolean columns standardized to True/False.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 8Ô∏è‚É£ Q6: Standardize Product Categories\n",
    "# ----------------------------------------\n",
    "df[\"category\"] = df[\"category\"].astype(str).str.title().str.strip()\n",
    "category_mapping = {\n",
    "    'electronics': 'Electronics',\n",
    "    'electronic': 'Electronics',\n",
    "    'electronics & accessories': 'Electronics',\n",
    "    'electronicss': 'Electronics'\n",
    "}\n",
    "df[\"category\"] = df[\"category\"].replace(category_mapping)\n",
    "print(\"üõí Product categories standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 9Ô∏è‚É£ Q7: Clean Delivery Days\n",
    "# ----------------------------------------\n",
    "def clean_delivery_days(x):\n",
    "    x = str(x).lower()\n",
    "    if \"same\" in x:\n",
    "        return 0\n",
    "    elif \"-\" in x:\n",
    "        parts = x.replace(\"days\", \"\").split(\"-\")\n",
    "        parts = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(parts) if parts else np.nan\n",
    "    elif x.replace('.', '', 1).isdigit():\n",
    "        return float(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].apply(clean_delivery_days)\n",
    "df.loc[df[\"delivery_days\"] < 0, \"delivery_days\"] = np.nan\n",
    "df.loc[df[\"delivery_days\"] > 30, \"delivery_days\"] = np.nan\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].fillna(df[\"delivery_days\"].median())\n",
    "print(\"üöö Delivery days cleaned and standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# üîü Q8: Handle Duplicate Transactions\n",
    "# ----------------------------------------\n",
    "# Create composite key\n",
    "df['dup_key'] = df[['customer_id', 'product_id', 'order_date', 'final_amount_inr']].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# Count occurrences\n",
    "dup_counts = df['dup_key'].value_counts().to_dict()\n",
    "df['dup_count'] = df['dup_key'].map(dup_counts)\n",
    "\n",
    "def is_same_timestamp(group):\n",
    "    return group['order_date'].nunique() == 1\n",
    "\n",
    "def classify_group(group):\n",
    "    if group['dup_count'].iloc[0] > 3 and not is_same_timestamp(group):\n",
    "        return 'bulk_order'\n",
    "    elif is_same_timestamp(group) and group['dup_count'].iloc[0] > 1:\n",
    "        return 'error'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "df['dup_status'] = df.groupby('dup_key').apply(classify_group).reset_index(drop=True)\n",
    "\n",
    "def handle_duplicates(df):\n",
    "    cleaned = pd.DataFrame()\n",
    "    for key, group in df.groupby('dup_key'):\n",
    "        status = group['dup_status'].iloc[0]\n",
    "        if status == 'bulk_order':\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "        elif status == 'error':\n",
    "            cleaned = pd.concat([cleaned, group.head(1)])\n",
    "        elif status == 'uncertain':\n",
    "            group['flag_for_review'] = True\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "    return cleaned.reset_index(drop=True)\n",
    "\n",
    "df = handle_duplicates(df)\n",
    "print(\"üîÅ Smart duplicate handling applied (bulk, error, uncertain).\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Q9: Detect and Fix Outlier Prices (Optimized Version)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Step 1: Compute IQR bounds (fallback rule)\n",
    "Q1 = df['original_price_inr'].quantile(0.25)\n",
    "Q3 = df['original_price_inr'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "\n",
    "# Step 2: Define logical price ranges by subcategory\n",
    "subcategory_price_ranges = {\n",
    "    'smartphones': (5000, 100000),\n",
    "    'smart_watch': (500, 15000),\n",
    "    'audio': (300, 20000),\n",
    "    'tablets': (5000, 60000),\n",
    "    'laptops': (20000, 150000),\n",
    "    'tv_&_entertainment': (10000, 150000),\n",
    "    'home_appliances': (2000, 80000),\n",
    "    'accessories': (100, 10000)\n",
    "}\n",
    "\n",
    "# Step 3: Correction function\n",
    "def correct_price(row):\n",
    "    price = row['original_price_inr']\n",
    "    if pd.isna(price):\n",
    "        return price  # skip NaN\n",
    "    \n",
    "    subcat = str(row.get('subcategory', '')).strip().lower().replace(' ', '_')\n",
    "    expected = subcategory_price_ranges.get(subcat)\n",
    "    \n",
    "    # Rule 1: Subcategory-based correction\n",
    "    if expected:\n",
    "        min_p, max_p = expected\n",
    "        if price > max_p * 10:      # unusually high\n",
    "            return price / 100\n",
    "        elif price < min_p / 10:    # unusually low\n",
    "            return price * 100\n",
    "    \n",
    "    # Rule 2: Generic statistical correction\n",
    "    if price > upper_bound * 50:   # extreme high outlier (e.g., 100x mistake)\n",
    "        return price / 100\n",
    "    elif price < lower_bound / 50: # extreme low outlier\n",
    "        return price * 100\n",
    "    \n",
    "    return price\n",
    "\n",
    "# Step 4: Apply the correction efficiently\n",
    "df['original_price_inr'] = df.apply(correct_price, axis=1)\n",
    "\n",
    "print(\"üìà Outlier prices detected and corrected using statistical + category rules.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Q10: Standardize Payment Methods\n",
    "# ----------------------------------------\n",
    "df[\"payment_method\"] = df[\"payment_method\"].astype(str).str.lower().replace({\n",
    "    \"upi\": \"UPI\",\n",
    "    \"phonepe\": \"UPI\",\n",
    "    \"googlepay\": \"UPI\",\n",
    "    \"credit_card\": \"Credit Card\",\n",
    "    \"cc\": \"Credit Card\",\n",
    "    \"debit_card\": \"Debit Card\",\n",
    "    \"cod\": \"Cash On Delivery\",\n",
    "    \"c.o.d\": \"Cash On Delivery\"\n",
    "})\n",
    "print(\"üí≥ Payment methods standardized.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# üßÆ Handle Missing Values (Age, Festival, Delivery)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def convert_age_group(value):\n",
    "    \"\"\"\n",
    "    Convert age range formats like '18-25', '26-35', '55+' into numeric averages.\n",
    "    Handle blanks and unknowns as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"unknown\", \"na\", \"n/a\", \"none\", \"\", \"missing\"]:\n",
    "        return np.nan\n",
    "    if '-' in value:\n",
    "        parts = value.replace('years', '').split('-')\n",
    "        nums = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(nums) if nums else np.nan\n",
    "    if '+' in value:\n",
    "        num = value.replace('+', '').replace('years', '').strip()\n",
    "        if num.isdigit():\n",
    "            return float(num) + 5  # assume midpoint\n",
    "        return np.nan\n",
    "    if value.replace('.', '', 1).isdigit():\n",
    "        return float(value)\n",
    "    return np.nan\n",
    "\n",
    "# Apply to age column\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].apply(convert_age_group)\n",
    "avg_age = round(df[\"customer_age_group\"].mean())\n",
    "df[\"customer_age_group\"].fillna(avg_age, inplace=True)\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].astype(int)\n",
    "print(f\"üë§ Age column cleaned. Missing and unknown values filled with average: {avg_age}\")\n",
    "\n",
    "# Festival name fill\n",
    "df[\"festival_name\"].fillna(\"Unknown\", inplace=True)\n",
    "print(\"üéâ Festival names missing values filled with 'Unknown'.\")\n",
    "\n",
    "# Delivery charges fill\n",
    "df[\"delivery_charges\"].fillna(0, inplace=True)\n",
    "print(\"üí∞ Delivery charges missing values replaced with 0.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# ‚úÖ Final Checks & Save Cleaned Dataset\n",
    "# ----------------------------------------\n",
    "df.info()\n",
    "\n",
    "output_path = r\"C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2018_cleaned.csv\"\n",
    "\n",
    "# ‚úÖ Ensure output folder exists before saving\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "print(\"‚úÖ Data Cleaning Completed & Saved Successfully:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05be83c2",
   "metadata": {},
   "source": [
    "### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dffb2f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded: (121605, 34)\n",
      "üóìÔ∏è Date column cleaned.\n",
      "üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\n",
      "üí∞ Price columns cleaned and converted to numeric.\n",
      "‚≠ê Ratings standardized to numeric scale.\n",
      "üèôÔ∏è City names standardized.\n",
      "üîò Boolean columns standardized to True/False.\n",
      "üõí Product categories standardized.\n",
      "üöö Delivery days cleaned and standardized.\n",
      "üîÅ Smart duplicate handling applied (bulk, error, uncertain).\n",
      "üìà Outlier prices detected and corrected using statistical + category rules.\n",
      "üí≥ Payment methods standardized.\n",
      "üë§ Age column cleaned. Missing and unknown values filled with average: 33\n",
      "üéâ Festival names missing values filled with 'Unknown'.\n",
      "üí∞ Delivery charges missing values replaced with 0.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121600 entries, 0 to 121599\n",
      "Data columns (total 38 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   transaction_id          121600 non-null  object \n",
      " 1   order_date              121600 non-null  object \n",
      " 2   customer_id             121600 non-null  object \n",
      " 3   product_id              121600 non-null  object \n",
      " 4   product_name            121600 non-null  object \n",
      " 5   category                121600 non-null  object \n",
      " 6   subcategory             121600 non-null  object \n",
      " 7   brand                   121600 non-null  object \n",
      " 8   original_price_inr      117987 non-null  float64\n",
      " 9   discount_percent        121600 non-null  float64\n",
      " 10  discounted_price_inr    121600 non-null  float64\n",
      " 11  quantity                121600 non-null  int64  \n",
      " 12  subtotal_inr            121600 non-null  float64\n",
      " 13  delivery_charges        121600 non-null  float64\n",
      " 14  final_amount_inr        121600 non-null  float64\n",
      " 15  customer_city           121600 non-null  object \n",
      " 16  customer_state          121600 non-null  object \n",
      " 17  customer_tier           121600 non-null  object \n",
      " 18  customer_spending_tier  121600 non-null  object \n",
      " 19  customer_age_group      121600 non-null  int64  \n",
      " 20  payment_method          121600 non-null  object \n",
      " 21  delivery_days           121600 non-null  float64\n",
      " 22  delivery_type           121600 non-null  object \n",
      " 23  is_prime_member         121600 non-null  bool   \n",
      " 24  is_festival_sale        121600 non-null  bool   \n",
      " 25  festival_name           121600 non-null  object \n",
      " 26  customer_rating         121600 non-null  float64\n",
      " 27  return_status           121600 non-null  object \n",
      " 28  order_month             121600 non-null  int64  \n",
      " 29  order_year              121600 non-null  int64  \n",
      " 30  order_quarter           121600 non-null  int64  \n",
      " 31  product_weight_kg       121600 non-null  float64\n",
      " 32  is_prime_eligible       121600 non-null  bool   \n",
      " 33  product_rating          121600 non-null  float64\n",
      " 34  dup_key                 121600 non-null  object \n",
      " 35  dup_count               121600 non-null  int64  \n",
      " 36  dup_status              121000 non-null  object \n",
      " 37  flag_for_review         120995 non-null  object \n",
      "dtypes: bool(3), float64(10), int64(6), object(19)\n",
      "memory usage: 32.8+ MB\n",
      "‚úÖ Data Cleaning Completed & Saved Successfully: C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2019_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# üßπ Amazon India Data Cleaning \n",
    "# Author: Desikan\n",
    "# Project: Amazon India 10-Year Sales Analytics\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # hide pandas 3.0 warnings\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# ----------------------------------------\n",
    "file_path = r\"C:\\Users\\desik\\Downloads\\Amazon raw dataset\\amazon_india_2019.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"‚úÖ Dataset Loaded:\", df.shape)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3Ô∏è‚É£ Q1: Clean and Standardize Dates\n",
    "# ----------------------------------------\n",
    "def clean_date(date_input):\n",
    "    try:\n",
    "        parsed_date = parser.parse(str(date_input), dayfirst=True)\n",
    "        return parsed_date.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"order_date\"] = df[\"order_date\"].apply(clean_date)\n",
    "print(\"üóìÔ∏è Date column cleaned.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4Ô∏è‚É£ Q2: Clean and Standardize Price Columns (Improved Version)\n",
    "# ----------------------------------------\n",
    "import re\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_price(value):\n",
    "    try:\n",
    "        value = str(value).strip()\n",
    "        # Remove currency symbols and unwanted characters\n",
    "        value = re.sub(r'[‚ÇπRs√¢‚Äö¬π]', '', value, flags=re.IGNORECASE)\n",
    "        value = value.replace(',', '')\n",
    "        \n",
    "        # Handle text like 'Price on Request' or blanks\n",
    "        if not re.match(r'^-?\\d+(\\.\\d+)?$', value):\n",
    "            return pd.NA\n",
    "        \n",
    "        # Convert to float and make sure negatives are positive\n",
    "        return abs(float(value))\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply cleaning to all relevant columns\n",
    "price_cols = [\"original_price_inr\", \"discounted_price_inr\", \"final_amount_inr\", \"delivery_charges\"]\n",
    "\n",
    "for col in price_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_price)\n",
    "\n",
    "print(\"üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\")\n",
    "\n",
    "print(\"üí∞ Price columns cleaned and converted to numeric.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5Ô∏è‚É£ Q3: Standardize Ratings (1.0 - 5.0)\n",
    "# ----------------------------------------\n",
    "def clean_rating(value):\n",
    "    try:\n",
    "        val = str(value).lower().replace(\"stars\", \"\").replace(\"/5\", \"\").replace(\"/5.0\", \"\").strip()\n",
    "        return float(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].apply(clean_rating)\n",
    "df[\"product_rating\"] = df[\"product_rating\"].apply(clean_rating)\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].fillna(df[\"customer_rating\"].median())\n",
    "print(\"‚≠ê Ratings standardized to numeric scale.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6Ô∏è‚É£ Q4: Standardize City Names\n",
    "# ----------------------------------------\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype(str).str.title().str.strip()\n",
    "city_mapping = {\n",
    "    'ahmedabad': 'Ahmedabad',\n",
    "    'aligarh': 'Aligarh',\n",
    "    'allahabad': 'Allahabad',\n",
    "    'bangalore': 'Bengaluru',\n",
    "    'banglore': 'Bengaluru',\n",
    "    'bengalore': 'Bengaluru',\n",
    "    'bengaluru': 'Bengaluru',\n",
    "    'bhubaneswar': 'Bhubaneswar',\n",
    "    'bombay': 'Mumbai',\n",
    "    'calcutta': 'Kolkata',\n",
    "    'chandigarh': 'Chandigarh',\n",
    "    'chenai': 'Chennai',\n",
    "    'chennai': 'Chennai',\n",
    "    'coimbatore': 'Coimbatore',\n",
    "    'customer_city': 'Unknown',\n",
    "    'delhi': 'Delhi',\n",
    "    'delhi ncr': 'Delhi',\n",
    "    'new delhi': 'Delhi',\n",
    "    'gorakhpur': 'Gorakhpur',\n",
    "    'hyderabad': 'Hyderabad',\n",
    "    'indore': 'Indore',\n",
    "    'jaipur': 'Jaipur',\n",
    "    'kanpur': 'Kanpur',\n",
    "    'kochi': 'Kochi',\n",
    "    'kolkata': 'Kolkata',\n",
    "    'lucknow': 'Lucknow',\n",
    "    'ludhiana': 'Ludhiana',\n",
    "    'madras': 'Chennai',\n",
    "    'meerut': 'Meerut',\n",
    "    'moradabad': 'Moradabad',\n",
    "    'mumba': 'Mumbai',\n",
    "    'mumbai': 'Mumbai',\n",
    "    'nagpur': 'Nagpur',\n",
    "    'patna': 'Patna',\n",
    "    'pune': 'Pune',\n",
    "    'saharanpur': 'Saharanpur',\n",
    "    'surat': 'Surat',\n",
    "    'vadodara': 'Vadodara',\n",
    "    'varanasi': 'Varanasi',\n",
    "    'visakhapatnam': 'Visakhapatnam'\n",
    "}\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(city_mapping)\n",
    "print(\"üèôÔ∏è City names standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7Ô∏è‚É£ Q5: Clean Boolean Columns\n",
    "# ----------------------------------------\n",
    "bool_cols = [\"is_prime_member\", \"is_prime_eligible\", \"is_festival_sale\"]\n",
    "\n",
    "for col in bool_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .replace({\n",
    "            \"yes\": True, \"true\": True, \"1\": True, \"y\": True,\n",
    "            \"no\": False, \"false\": False, \"0\": False, \"n\": False\n",
    "        })\n",
    "    )\n",
    "    df[col] = df[col].astype(bool)\n",
    "\n",
    "print(\"üîò Boolean columns standardized to True/False.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 8Ô∏è‚É£ Q6: Standardize Product Categories\n",
    "# ----------------------------------------\n",
    "df[\"category\"] = df[\"category\"].astype(str).str.title().str.strip()\n",
    "category_mapping = {\n",
    "    'electronics': 'Electronics',\n",
    "    'electronic': 'Electronics',\n",
    "    'electronics & accessories': 'Electronics',\n",
    "    'electronicss': 'Electronics'\n",
    "}\n",
    "df[\"category\"] = df[\"category\"].replace(category_mapping)\n",
    "print(\"üõí Product categories standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 9Ô∏è‚É£ Q7: Clean Delivery Days\n",
    "# ----------------------------------------\n",
    "def clean_delivery_days(x):\n",
    "    x = str(x).lower()\n",
    "    if \"same\" in x:\n",
    "        return 0\n",
    "    elif \"-\" in x:\n",
    "        parts = x.replace(\"days\", \"\").split(\"-\")\n",
    "        parts = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(parts) if parts else np.nan\n",
    "    elif x.replace('.', '', 1).isdigit():\n",
    "        return float(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].apply(clean_delivery_days)\n",
    "df.loc[df[\"delivery_days\"] < 0, \"delivery_days\"] = np.nan\n",
    "df.loc[df[\"delivery_days\"] > 30, \"delivery_days\"] = np.nan\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].fillna(df[\"delivery_days\"].median())\n",
    "print(\"üöö Delivery days cleaned and standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# üîü Q8: Handle Duplicate Transactions\n",
    "# ----------------------------------------\n",
    "# Create composite key\n",
    "df['dup_key'] = df[['customer_id', 'product_id', 'order_date', 'final_amount_inr']].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# Count occurrences\n",
    "dup_counts = df['dup_key'].value_counts().to_dict()\n",
    "df['dup_count'] = df['dup_key'].map(dup_counts)\n",
    "\n",
    "def is_same_timestamp(group):\n",
    "    return group['order_date'].nunique() == 1\n",
    "\n",
    "def classify_group(group):\n",
    "    if group['dup_count'].iloc[0] > 3 and not is_same_timestamp(group):\n",
    "        return 'bulk_order'\n",
    "    elif is_same_timestamp(group) and group['dup_count'].iloc[0] > 1:\n",
    "        return 'error'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "df['dup_status'] = df.groupby('dup_key').apply(classify_group).reset_index(drop=True)\n",
    "\n",
    "def handle_duplicates(df):\n",
    "    cleaned = pd.DataFrame()\n",
    "    for key, group in df.groupby('dup_key'):\n",
    "        status = group['dup_status'].iloc[0]\n",
    "        if status == 'bulk_order':\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "        elif status == 'error':\n",
    "            cleaned = pd.concat([cleaned, group.head(1)])\n",
    "        elif status == 'uncertain':\n",
    "            group['flag_for_review'] = True\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "    return cleaned.reset_index(drop=True)\n",
    "\n",
    "df = handle_duplicates(df)\n",
    "print(\"üîÅ Smart duplicate handling applied (bulk, error, uncertain).\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Q9: Detect and Fix Outlier Prices (Optimized Version)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Step 1: Compute IQR bounds (fallback rule)\n",
    "Q1 = df['original_price_inr'].quantile(0.25)\n",
    "Q3 = df['original_price_inr'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "\n",
    "# Step 2: Define logical price ranges by subcategory\n",
    "subcategory_price_ranges = {\n",
    "    'smartphones': (5000, 100000),\n",
    "    'smart_watch': (500, 15000),\n",
    "    'audio': (300, 20000),\n",
    "    'tablets': (5000, 60000),\n",
    "    'laptops': (20000, 150000),\n",
    "    'tv_&_entertainment': (10000, 150000),\n",
    "    'home_appliances': (2000, 80000),\n",
    "    'accessories': (100, 10000)\n",
    "}\n",
    "\n",
    "# Step 3: Correction function\n",
    "def correct_price(row):\n",
    "    price = row['original_price_inr']\n",
    "    if pd.isna(price):\n",
    "        return price  # skip NaN\n",
    "    \n",
    "    subcat = str(row.get('subcategory', '')).strip().lower().replace(' ', '_')\n",
    "    expected = subcategory_price_ranges.get(subcat)\n",
    "    \n",
    "    # Rule 1: Subcategory-based correction\n",
    "    if expected:\n",
    "        min_p, max_p = expected\n",
    "        if price > max_p * 10:      # unusually high\n",
    "            return price / 100\n",
    "        elif price < min_p / 10:    # unusually low\n",
    "            return price * 100\n",
    "    \n",
    "    # Rule 2: Generic statistical correction\n",
    "    if price > upper_bound * 50:   # extreme high outlier (e.g., 100x mistake)\n",
    "        return price / 100\n",
    "    elif price < lower_bound / 50: # extreme low outlier\n",
    "        return price * 100\n",
    "    \n",
    "    return price\n",
    "\n",
    "# Step 4: Apply the correction efficiently\n",
    "df['original_price_inr'] = df.apply(correct_price, axis=1)\n",
    "\n",
    "print(\"üìà Outlier prices detected and corrected using statistical + category rules.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Q10: Standardize Payment Methods\n",
    "# ----------------------------------------\n",
    "df[\"payment_method\"] = df[\"payment_method\"].astype(str).str.lower().replace({\n",
    "    \"upi\": \"UPI\",\n",
    "    \"phonepe\": \"UPI\",\n",
    "    \"googlepay\": \"UPI\",\n",
    "    \"credit_card\": \"Credit Card\",\n",
    "    \"cc\": \"Credit Card\",\n",
    "    \"debit_card\": \"Debit Card\",\n",
    "    \"cod\": \"Cash On Delivery\",\n",
    "    \"c.o.d\": \"Cash On Delivery\"\n",
    "})\n",
    "print(\"üí≥ Payment methods standardized.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# üßÆ Handle Missing Values (Age, Festival, Delivery)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def convert_age_group(value):\n",
    "    \"\"\"\n",
    "    Convert age range formats like '18-25', '26-35', '55+' into numeric averages.\n",
    "    Handle blanks and unknowns as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"unknown\", \"na\", \"n/a\", \"none\", \"\", \"missing\"]:\n",
    "        return np.nan\n",
    "    if '-' in value:\n",
    "        parts = value.replace('years', '').split('-')\n",
    "        nums = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(nums) if nums else np.nan\n",
    "    if '+' in value:\n",
    "        num = value.replace('+', '').replace('years', '').strip()\n",
    "        if num.isdigit():\n",
    "            return float(num) + 5  # assume midpoint\n",
    "        return np.nan\n",
    "    if value.replace('.', '', 1).isdigit():\n",
    "        return float(value)\n",
    "    return np.nan\n",
    "\n",
    "# Apply to age column\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].apply(convert_age_group)\n",
    "avg_age = round(df[\"customer_age_group\"].mean())\n",
    "df[\"customer_age_group\"].fillna(avg_age, inplace=True)\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].astype(int)\n",
    "print(f\"üë§ Age column cleaned. Missing and unknown values filled with average: {avg_age}\")\n",
    "\n",
    "# Festival name fill\n",
    "df[\"festival_name\"].fillna(\"Unknown\", inplace=True)\n",
    "print(\"üéâ Festival names missing values filled with 'Unknown'.\")\n",
    "\n",
    "# Delivery charges fill\n",
    "df[\"delivery_charges\"].fillna(0, inplace=True)\n",
    "print(\"üí∞ Delivery charges missing values replaced with 0.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# ‚úÖ Final Checks & Save Cleaned Dataset\n",
    "# ----------------------------------------\n",
    "df.info()\n",
    "\n",
    "output_path = r\"C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2019_cleaned.csv\"\n",
    "\n",
    "# ‚úÖ Ensure output folder exists before saving\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "print(\"‚úÖ Data Cleaning Completed & Saved Successfully:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0bb0c6",
   "metadata": {},
   "source": [
    "### 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc811913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded: (143715, 34)\n",
      "üóìÔ∏è Date column cleaned.\n",
      "üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\n",
      "üí∞ Price columns cleaned and converted to numeric.\n",
      "‚≠ê Ratings standardized to numeric scale.\n",
      "üèôÔ∏è City names standardized.\n",
      "üîò Boolean columns standardized to True/False.\n",
      "üõí Product categories standardized.\n",
      "üöö Delivery days cleaned and standardized.\n",
      "üîÅ Smart duplicate handling applied (bulk, error, uncertain).\n",
      "üìà Outlier prices detected and corrected using statistical + category rules.\n",
      "üí≥ Payment methods standardized.\n",
      "üë§ Age column cleaned. Missing and unknown values filled with average: 33\n",
      "üéâ Festival names missing values filled with 'Unknown'.\n",
      "üí∞ Delivery charges missing values replaced with 0.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143711 entries, 0 to 143710\n",
      "Data columns (total 38 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   transaction_id          143711 non-null  object \n",
      " 1   order_date              143711 non-null  object \n",
      " 2   customer_id             143711 non-null  object \n",
      " 3   product_id              143711 non-null  object \n",
      " 4   product_name            143711 non-null  object \n",
      " 5   category                143711 non-null  object \n",
      " 6   subcategory             143711 non-null  object \n",
      " 7   brand                   143711 non-null  object \n",
      " 8   original_price_inr      139420 non-null  float64\n",
      " 9   discount_percent        143711 non-null  float64\n",
      " 10  discounted_price_inr    143711 non-null  float64\n",
      " 11  quantity                143711 non-null  int64  \n",
      " 12  subtotal_inr            143711 non-null  float64\n",
      " 13  delivery_charges        143711 non-null  float64\n",
      " 14  final_amount_inr        143711 non-null  float64\n",
      " 15  customer_city           143711 non-null  object \n",
      " 16  customer_state          143711 non-null  object \n",
      " 17  customer_tier           143711 non-null  object \n",
      " 18  customer_spending_tier  143711 non-null  object \n",
      " 19  customer_age_group      143711 non-null  int64  \n",
      " 20  payment_method          143711 non-null  object \n",
      " 21  delivery_days           143711 non-null  float64\n",
      " 22  delivery_type           143711 non-null  object \n",
      " 23  is_prime_member         143711 non-null  bool   \n",
      " 24  is_festival_sale        143711 non-null  bool   \n",
      " 25  festival_name           143711 non-null  object \n",
      " 26  customer_rating         143711 non-null  float64\n",
      " 27  return_status           143711 non-null  object \n",
      " 28  order_month             143711 non-null  int64  \n",
      " 29  order_year              143711 non-null  int64  \n",
      " 30  order_quarter           143711 non-null  int64  \n",
      " 31  product_weight_kg       143711 non-null  float64\n",
      " 32  is_prime_eligible       143711 non-null  bool   \n",
      " 33  product_rating          143711 non-null  float64\n",
      " 34  dup_key                 143711 non-null  object \n",
      " 35  dup_count               143711 non-null  int64  \n",
      " 36  dup_status              143000 non-null  object \n",
      " 37  flag_for_review         142996 non-null  object \n",
      "dtypes: bool(3), float64(10), int64(6), object(19)\n",
      "memory usage: 38.8+ MB\n",
      "‚úÖ Data Cleaning Completed & Saved Successfully: C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2020_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# üßπ Amazon India Data Cleaning \n",
    "# Author: Desikan\n",
    "# Project: Amazon India 10-Year Sales Analytics\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # hide pandas 3.0 warnings\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# ----------------------------------------\n",
    "file_path = r\"C:\\Users\\desik\\Downloads\\Amazon raw dataset\\amazon_india_2020.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"‚úÖ Dataset Loaded:\", df.shape)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3Ô∏è‚É£ Q1: Clean and Standardize Dates\n",
    "# ----------------------------------------\n",
    "def clean_date(date_input):\n",
    "    try:\n",
    "        parsed_date = parser.parse(str(date_input), dayfirst=True)\n",
    "        return parsed_date.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"order_date\"] = df[\"order_date\"].apply(clean_date)\n",
    "print(\"üóìÔ∏è Date column cleaned.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4Ô∏è‚É£ Q2: Clean and Standardize Price Columns (Improved Version)\n",
    "# ----------------------------------------\n",
    "import re\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_price(value):\n",
    "    try:\n",
    "        value = str(value).strip()\n",
    "        # Remove currency symbols and unwanted characters\n",
    "        value = re.sub(r'[‚ÇπRs√¢‚Äö¬π]', '', value, flags=re.IGNORECASE)\n",
    "        value = value.replace(',', '')\n",
    "        \n",
    "        # Handle text like 'Price on Request' or blanks\n",
    "        if not re.match(r'^-?\\d+(\\.\\d+)?$', value):\n",
    "            return pd.NA\n",
    "        \n",
    "        # Convert to float and make sure negatives are positive\n",
    "        return abs(float(value))\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply cleaning to all relevant columns\n",
    "price_cols = [\"original_price_inr\", \"discounted_price_inr\", \"final_amount_inr\", \"delivery_charges\"]\n",
    "\n",
    "for col in price_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_price)\n",
    "\n",
    "print(\"üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\")\n",
    "\n",
    "print(\"üí∞ Price columns cleaned and converted to numeric.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5Ô∏è‚É£ Q3: Standardize Ratings (1.0 - 5.0)\n",
    "# ----------------------------------------\n",
    "def clean_rating(value):\n",
    "    try:\n",
    "        val = str(value).lower().replace(\"stars\", \"\").replace(\"/5\", \"\").replace(\"/5.0\", \"\").strip()\n",
    "        return float(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].apply(clean_rating)\n",
    "df[\"product_rating\"] = df[\"product_rating\"].apply(clean_rating)\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].fillna(df[\"customer_rating\"].median())\n",
    "print(\"‚≠ê Ratings standardized to numeric scale.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6Ô∏è‚É£ Q4: Standardize City Names\n",
    "# ----------------------------------------\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype(str).str.title().str.strip()\n",
    "city_mapping = {\n",
    "    'ahmedabad': 'Ahmedabad',\n",
    "    'aligarh': 'Aligarh',\n",
    "    'allahabad': 'Allahabad',\n",
    "    'bangalore': 'Bengaluru',\n",
    "    'banglore': 'Bengaluru',\n",
    "    'bengalore': 'Bengaluru',\n",
    "    'bengaluru': 'Bengaluru',\n",
    "    'bhubaneswar': 'Bhubaneswar',\n",
    "    'bombay': 'Mumbai',\n",
    "    'calcutta': 'Kolkata',\n",
    "    'chandigarh': 'Chandigarh',\n",
    "    'chenai': 'Chennai',\n",
    "    'chennai': 'Chennai',\n",
    "    'coimbatore': 'Coimbatore',\n",
    "    'customer_city': 'Unknown',\n",
    "    'delhi': 'Delhi',\n",
    "    'delhi ncr': 'Delhi',\n",
    "    'new delhi': 'Delhi',\n",
    "    'gorakhpur': 'Gorakhpur',\n",
    "    'hyderabad': 'Hyderabad',\n",
    "    'indore': 'Indore',\n",
    "    'jaipur': 'Jaipur',\n",
    "    'kanpur': 'Kanpur',\n",
    "    'kochi': 'Kochi',\n",
    "    'kolkata': 'Kolkata',\n",
    "    'lucknow': 'Lucknow',\n",
    "    'ludhiana': 'Ludhiana',\n",
    "    'madras': 'Chennai',\n",
    "    'meerut': 'Meerut',\n",
    "    'moradabad': 'Moradabad',\n",
    "    'mumba': 'Mumbai',\n",
    "    'mumbai': 'Mumbai',\n",
    "    'nagpur': 'Nagpur',\n",
    "    'patna': 'Patna',\n",
    "    'pune': 'Pune',\n",
    "    'saharanpur': 'Saharanpur',\n",
    "    'surat': 'Surat',\n",
    "    'vadodara': 'Vadodara',\n",
    "    'varanasi': 'Varanasi',\n",
    "    'visakhapatnam': 'Visakhapatnam'\n",
    "}\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(city_mapping)\n",
    "print(\"üèôÔ∏è City names standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7Ô∏è‚É£ Q5: Clean Boolean Columns\n",
    "# ----------------------------------------\n",
    "bool_cols = [\"is_prime_member\", \"is_prime_eligible\", \"is_festival_sale\"]\n",
    "\n",
    "for col in bool_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .replace({\n",
    "            \"yes\": True, \"true\": True, \"1\": True, \"y\": True,\n",
    "            \"no\": False, \"false\": False, \"0\": False, \"n\": False\n",
    "        })\n",
    "    )\n",
    "    df[col] = df[col].astype(bool)\n",
    "\n",
    "print(\"üîò Boolean columns standardized to True/False.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 8Ô∏è‚É£ Q6: Standardize Product Categories\n",
    "# ----------------------------------------\n",
    "df[\"category\"] = df[\"category\"].astype(str).str.title().str.strip()\n",
    "category_mapping = {\n",
    "    'electronics': 'Electronics',\n",
    "    'electronic': 'Electronics',\n",
    "    'electronics & accessories': 'Electronics',\n",
    "    'electronicss': 'Electronics'\n",
    "}\n",
    "df[\"category\"] = df[\"category\"].replace(category_mapping)\n",
    "print(\"üõí Product categories standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 9Ô∏è‚É£ Q7: Clean Delivery Days\n",
    "# ----------------------------------------\n",
    "def clean_delivery_days(x):\n",
    "    x = str(x).lower()\n",
    "    if \"same\" in x:\n",
    "        return 0\n",
    "    elif \"-\" in x:\n",
    "        parts = x.replace(\"days\", \"\").split(\"-\")\n",
    "        parts = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(parts) if parts else np.nan\n",
    "    elif x.replace('.', '', 1).isdigit():\n",
    "        return float(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].apply(clean_delivery_days)\n",
    "df.loc[df[\"delivery_days\"] < 0, \"delivery_days\"] = np.nan\n",
    "df.loc[df[\"delivery_days\"] > 30, \"delivery_days\"] = np.nan\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].fillna(df[\"delivery_days\"].median())\n",
    "print(\"üöö Delivery days cleaned and standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# üîü Q8: Handle Duplicate Transactions\n",
    "# ----------------------------------------\n",
    "# Create composite key\n",
    "df['dup_key'] = df[['customer_id', 'product_id', 'order_date', 'final_amount_inr']].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# Count occurrences\n",
    "dup_counts = df['dup_key'].value_counts().to_dict()\n",
    "df['dup_count'] = df['dup_key'].map(dup_counts)\n",
    "\n",
    "def is_same_timestamp(group):\n",
    "    return group['order_date'].nunique() == 1\n",
    "\n",
    "def classify_group(group):\n",
    "    if group['dup_count'].iloc[0] > 3 and not is_same_timestamp(group):\n",
    "        return 'bulk_order'\n",
    "    elif is_same_timestamp(group) and group['dup_count'].iloc[0] > 1:\n",
    "        return 'error'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "df['dup_status'] = df.groupby('dup_key').apply(classify_group).reset_index(drop=True)\n",
    "\n",
    "def handle_duplicates(df):\n",
    "    cleaned = pd.DataFrame()\n",
    "    for key, group in df.groupby('dup_key'):\n",
    "        status = group['dup_status'].iloc[0]\n",
    "        if status == 'bulk_order':\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "        elif status == 'error':\n",
    "            cleaned = pd.concat([cleaned, group.head(1)])\n",
    "        elif status == 'uncertain':\n",
    "            group['flag_for_review'] = True\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "    return cleaned.reset_index(drop=True)\n",
    "\n",
    "df = handle_duplicates(df)\n",
    "print(\"üîÅ Smart duplicate handling applied (bulk, error, uncertain).\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Q9: Detect and Fix Outlier Prices (Optimized Version)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Step 1: Compute IQR bounds (fallback rule)\n",
    "Q1 = df['original_price_inr'].quantile(0.25)\n",
    "Q3 = df['original_price_inr'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "\n",
    "# Step 2: Define logical price ranges by subcategory\n",
    "subcategory_price_ranges = {\n",
    "    'smartphones': (5000, 100000),\n",
    "    'smart_watch': (500, 15000),\n",
    "    'audio': (300, 20000),\n",
    "    'tablets': (5000, 60000),\n",
    "    'laptops': (20000, 150000),\n",
    "    'tv_&_entertainment': (10000, 150000),\n",
    "    'home_appliances': (2000, 80000),\n",
    "    'accessories': (100, 10000)\n",
    "}\n",
    "\n",
    "# Step 3: Correction function\n",
    "def correct_price(row):\n",
    "    price = row['original_price_inr']\n",
    "    if pd.isna(price):\n",
    "        return price  # skip NaN\n",
    "    \n",
    "    subcat = str(row.get('subcategory', '')).strip().lower().replace(' ', '_')\n",
    "    expected = subcategory_price_ranges.get(subcat)\n",
    "    \n",
    "    # Rule 1: Subcategory-based correction\n",
    "    if expected:\n",
    "        min_p, max_p = expected\n",
    "        if price > max_p * 10:      # unusually high\n",
    "            return price / 100\n",
    "        elif price < min_p / 10:    # unusually low\n",
    "            return price * 100\n",
    "    \n",
    "    # Rule 2: Generic statistical correction\n",
    "    if price > upper_bound * 50:   # extreme high outlier (e.g., 100x mistake)\n",
    "        return price / 100\n",
    "    elif price < lower_bound / 50: # extreme low outlier\n",
    "        return price * 100\n",
    "    \n",
    "    return price\n",
    "\n",
    "# Step 4: Apply the correction efficiently\n",
    "df['original_price_inr'] = df.apply(correct_price, axis=1)\n",
    "\n",
    "print(\"üìà Outlier prices detected and corrected using statistical + category rules.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Q10: Standardize Payment Methods\n",
    "# ----------------------------------------\n",
    "df[\"payment_method\"] = df[\"payment_method\"].astype(str).str.lower().replace({\n",
    "    \"upi\": \"UPI\",\n",
    "    \"phonepe\": \"UPI\",\n",
    "    \"googlepay\": \"UPI\",\n",
    "    \"credit_card\": \"Credit Card\",\n",
    "    \"cc\": \"Credit Card\",\n",
    "    \"debit_card\": \"Debit Card\",\n",
    "    \"cod\": \"Cash On Delivery\",\n",
    "    \"c.o.d\": \"Cash On Delivery\"\n",
    "})\n",
    "print(\"üí≥ Payment methods standardized.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# üßÆ Handle Missing Values (Age, Festival, Delivery)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def convert_age_group(value):\n",
    "    \"\"\"\n",
    "    Convert age range formats like '18-25', '26-35', '55+' into numeric averages.\n",
    "    Handle blanks and unknowns as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"unknown\", \"na\", \"n/a\", \"none\", \"\", \"missing\"]:\n",
    "        return np.nan\n",
    "    if '-' in value:\n",
    "        parts = value.replace('years', '').split('-')\n",
    "        nums = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(nums) if nums else np.nan\n",
    "    if '+' in value:\n",
    "        num = value.replace('+', '').replace('years', '').strip()\n",
    "        if num.isdigit():\n",
    "            return float(num) + 5  # assume midpoint\n",
    "        return np.nan\n",
    "    if value.replace('.', '', 1).isdigit():\n",
    "        return float(value)\n",
    "    return np.nan\n",
    "\n",
    "# Apply to age column\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].apply(convert_age_group)\n",
    "avg_age = round(df[\"customer_age_group\"].mean())\n",
    "df[\"customer_age_group\"].fillna(avg_age, inplace=True)\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].astype(int)\n",
    "print(f\"üë§ Age column cleaned. Missing and unknown values filled with average: {avg_age}\")\n",
    "\n",
    "# Festival name fill\n",
    "df[\"festival_name\"].fillna(\"Unknown\", inplace=True)\n",
    "print(\"üéâ Festival names missing values filled with 'Unknown'.\")\n",
    "\n",
    "# Delivery charges fill\n",
    "df[\"delivery_charges\"].fillna(0, inplace=True)\n",
    "print(\"üí∞ Delivery charges missing values replaced with 0.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# ‚úÖ Final Checks & Save Cleaned Dataset\n",
    "# ----------------------------------------\n",
    "df.info()\n",
    "\n",
    "output_path = r\"C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2020_cleaned.csv\"\n",
    "\n",
    "# ‚úÖ Ensure output folder exists before saving\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "print(\"‚úÖ Data Cleaning Completed & Saved Successfully:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3a27f",
   "metadata": {},
   "source": [
    "### 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2942591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded: (138187, 34)\n",
      "üóìÔ∏è Date column cleaned.\n",
      "üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\n",
      "üí∞ Price columns cleaned and converted to numeric.\n",
      "‚≠ê Ratings standardized to numeric scale.\n",
      "üèôÔ∏è City names standardized.\n",
      "üîò Boolean columns standardized to True/False.\n",
      "üõí Product categories standardized.\n",
      "üöö Delivery days cleaned and standardized.\n",
      "üîÅ Smart duplicate handling applied (bulk, error, uncertain).\n",
      "üìà Outlier prices detected and corrected using statistical + category rules.\n",
      "üí≥ Payment methods standardized.\n",
      "üë§ Age column cleaned. Missing and unknown values filled with average: 33\n",
      "üéâ Festival names missing values filled with 'Unknown'.\n",
      "üí∞ Delivery charges missing values replaced with 0.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 138183 entries, 0 to 138182\n",
      "Data columns (total 38 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   transaction_id          138183 non-null  object \n",
      " 1   order_date              138183 non-null  object \n",
      " 2   customer_id             138183 non-null  object \n",
      " 3   product_id              138183 non-null  object \n",
      " 4   product_name            138183 non-null  object \n",
      " 5   category                138183 non-null  object \n",
      " 6   subcategory             138183 non-null  object \n",
      " 7   brand                   138183 non-null  object \n",
      " 8   original_price_inr      134060 non-null  float64\n",
      " 9   discount_percent        138183 non-null  float64\n",
      " 10  discounted_price_inr    138183 non-null  float64\n",
      " 11  quantity                138183 non-null  int64  \n",
      " 12  subtotal_inr            138183 non-null  float64\n",
      " 13  delivery_charges        138183 non-null  float64\n",
      " 14  final_amount_inr        138183 non-null  float64\n",
      " 15  customer_city           138183 non-null  object \n",
      " 16  customer_state          138183 non-null  object \n",
      " 17  customer_tier           138183 non-null  object \n",
      " 18  customer_spending_tier  138183 non-null  object \n",
      " 19  customer_age_group      138183 non-null  int64  \n",
      " 20  payment_method          138183 non-null  object \n",
      " 21  delivery_days           138183 non-null  float64\n",
      " 22  delivery_type           138183 non-null  object \n",
      " 23  is_prime_member         138183 non-null  bool   \n",
      " 24  is_festival_sale        138183 non-null  bool   \n",
      " 25  festival_name           138183 non-null  object \n",
      " 26  customer_rating         138183 non-null  float64\n",
      " 27  return_status           138183 non-null  object \n",
      " 28  order_month             138183 non-null  int64  \n",
      " 29  order_year              138183 non-null  int64  \n",
      " 30  order_quarter           138183 non-null  int64  \n",
      " 31  product_weight_kg       138183 non-null  float64\n",
      " 32  is_prime_eligible       138183 non-null  bool   \n",
      " 33  product_rating          138183 non-null  float64\n",
      " 34  dup_key                 138183 non-null  object \n",
      " 35  dup_count               138183 non-null  int64  \n",
      " 36  dup_status              137500 non-null  object \n",
      " 37  flag_for_review         137496 non-null  object \n",
      "dtypes: bool(3), float64(10), int64(6), object(19)\n",
      "memory usage: 37.3+ MB\n",
      "‚úÖ Data Cleaning Completed & Saved Successfully: C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2021_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# üßπ Amazon India Data Cleaning \n",
    "# Author: Desikan\n",
    "# Project: Amazon India 10-Year Sales Analytics\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # hide pandas 3.0 warnings\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# ----------------------------------------\n",
    "file_path = r\"C:\\Users\\desik\\Downloads\\Amazon raw dataset\\amazon_india_2021.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"‚úÖ Dataset Loaded:\", df.shape)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3Ô∏è‚É£ Q1: Clean and Standardize Dates\n",
    "# ----------------------------------------\n",
    "def clean_date(date_input):\n",
    "    try:\n",
    "        parsed_date = parser.parse(str(date_input), dayfirst=True)\n",
    "        return parsed_date.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"order_date\"] = df[\"order_date\"].apply(clean_date)\n",
    "print(\"üóìÔ∏è Date column cleaned.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4Ô∏è‚É£ Q2: Clean and Standardize Price Columns (Improved Version)\n",
    "# ----------------------------------------\n",
    "import re\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_price(value):\n",
    "    try:\n",
    "        value = str(value).strip()\n",
    "        # Remove currency symbols and unwanted characters\n",
    "        value = re.sub(r'[‚ÇπRs√¢‚Äö¬π]', '', value, flags=re.IGNORECASE)\n",
    "        value = value.replace(',', '')\n",
    "        \n",
    "        # Handle text like 'Price on Request' or blanks\n",
    "        if not re.match(r'^-?\\d+(\\.\\d+)?$', value):\n",
    "            return pd.NA\n",
    "        \n",
    "        # Convert to float and make sure negatives are positive\n",
    "        return abs(float(value))\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply cleaning to all relevant columns\n",
    "price_cols = [\"original_price_inr\", \"discounted_price_inr\", \"final_amount_inr\", \"delivery_charges\"]\n",
    "\n",
    "for col in price_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_price)\n",
    "\n",
    "print(\"üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\")\n",
    "\n",
    "print(\"üí∞ Price columns cleaned and converted to numeric.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5Ô∏è‚É£ Q3: Standardize Ratings (1.0 - 5.0)\n",
    "# ----------------------------------------\n",
    "def clean_rating(value):\n",
    "    try:\n",
    "        val = str(value).lower().replace(\"stars\", \"\").replace(\"/5\", \"\").replace(\"/5.0\", \"\").strip()\n",
    "        return float(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].apply(clean_rating)\n",
    "df[\"product_rating\"] = df[\"product_rating\"].apply(clean_rating)\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].fillna(df[\"customer_rating\"].median())\n",
    "print(\"‚≠ê Ratings standardized to numeric scale.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6Ô∏è‚É£ Q4: Standardize City Names\n",
    "# ----------------------------------------\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype(str).str.title().str.strip()\n",
    "city_mapping = {\n",
    "    'ahmedabad': 'Ahmedabad',\n",
    "    'aligarh': 'Aligarh',\n",
    "    'allahabad': 'Allahabad',\n",
    "    'bangalore': 'Bengaluru',\n",
    "    'banglore': 'Bengaluru',\n",
    "    'bengalore': 'Bengaluru',\n",
    "    'bengaluru': 'Bengaluru',\n",
    "    'bhubaneswar': 'Bhubaneswar',\n",
    "    'bombay': 'Mumbai',\n",
    "    'calcutta': 'Kolkata',\n",
    "    'chandigarh': 'Chandigarh',\n",
    "    'chenai': 'Chennai',\n",
    "    'chennai': 'Chennai',\n",
    "    'coimbatore': 'Coimbatore',\n",
    "    'customer_city': 'Unknown',\n",
    "    'delhi': 'Delhi',\n",
    "    'delhi ncr': 'Delhi',\n",
    "    'new delhi': 'Delhi',\n",
    "    'gorakhpur': 'Gorakhpur',\n",
    "    'hyderabad': 'Hyderabad',\n",
    "    'indore': 'Indore',\n",
    "    'jaipur': 'Jaipur',\n",
    "    'kanpur': 'Kanpur',\n",
    "    'kochi': 'Kochi',\n",
    "    'kolkata': 'Kolkata',\n",
    "    'lucknow': 'Lucknow',\n",
    "    'ludhiana': 'Ludhiana',\n",
    "    'madras': 'Chennai',\n",
    "    'meerut': 'Meerut',\n",
    "    'moradabad': 'Moradabad',\n",
    "    'mumba': 'Mumbai',\n",
    "    'mumbai': 'Mumbai',\n",
    "    'nagpur': 'Nagpur',\n",
    "    'patna': 'Patna',\n",
    "    'pune': 'Pune',\n",
    "    'saharanpur': 'Saharanpur',\n",
    "    'surat': 'Surat',\n",
    "    'vadodara': 'Vadodara',\n",
    "    'varanasi': 'Varanasi',\n",
    "    'visakhapatnam': 'Visakhapatnam'\n",
    "}\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(city_mapping)\n",
    "print(\"üèôÔ∏è City names standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7Ô∏è‚É£ Q5: Clean Boolean Columns\n",
    "# ----------------------------------------\n",
    "bool_cols = [\"is_prime_member\", \"is_prime_eligible\", \"is_festival_sale\"]\n",
    "\n",
    "for col in bool_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .replace({\n",
    "            \"yes\": True, \"true\": True, \"1\": True, \"y\": True,\n",
    "            \"no\": False, \"false\": False, \"0\": False, \"n\": False\n",
    "        })\n",
    "    )\n",
    "    df[col] = df[col].astype(bool)\n",
    "\n",
    "print(\"üîò Boolean columns standardized to True/False.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 8Ô∏è‚É£ Q6: Standardize Product Categories\n",
    "# ----------------------------------------\n",
    "df[\"category\"] = df[\"category\"].astype(str).str.title().str.strip()\n",
    "category_mapping = {\n",
    "    'electronics': 'Electronics',\n",
    "    'electronic': 'Electronics',\n",
    "    'electronics & accessories': 'Electronics',\n",
    "    'electronicss': 'Electronics'\n",
    "}\n",
    "df[\"category\"] = df[\"category\"].replace(category_mapping)\n",
    "print(\"üõí Product categories standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 9Ô∏è‚É£ Q7: Clean Delivery Days\n",
    "# ----------------------------------------\n",
    "def clean_delivery_days(x):\n",
    "    x = str(x).lower()\n",
    "    if \"same\" in x:\n",
    "        return 0\n",
    "    elif \"-\" in x:\n",
    "        parts = x.replace(\"days\", \"\").split(\"-\")\n",
    "        parts = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(parts) if parts else np.nan\n",
    "    elif x.replace('.', '', 1).isdigit():\n",
    "        return float(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].apply(clean_delivery_days)\n",
    "df.loc[df[\"delivery_days\"] < 0, \"delivery_days\"] = np.nan\n",
    "df.loc[df[\"delivery_days\"] > 30, \"delivery_days\"] = np.nan\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].fillna(df[\"delivery_days\"].median())\n",
    "print(\"üöö Delivery days cleaned and standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# üîü Q8: Handle Duplicate Transactions\n",
    "# ----------------------------------------\n",
    "# Create composite key\n",
    "df['dup_key'] = df[['customer_id', 'product_id', 'order_date', 'final_amount_inr']].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# Count occurrences\n",
    "dup_counts = df['dup_key'].value_counts().to_dict()\n",
    "df['dup_count'] = df['dup_key'].map(dup_counts)\n",
    "\n",
    "def is_same_timestamp(group):\n",
    "    return group['order_date'].nunique() == 1\n",
    "\n",
    "def classify_group(group):\n",
    "    if group['dup_count'].iloc[0] > 3 and not is_same_timestamp(group):\n",
    "        return 'bulk_order'\n",
    "    elif is_same_timestamp(group) and group['dup_count'].iloc[0] > 1:\n",
    "        return 'error'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "df['dup_status'] = df.groupby('dup_key').apply(classify_group).reset_index(drop=True)\n",
    "\n",
    "def handle_duplicates(df):\n",
    "    cleaned = pd.DataFrame()\n",
    "    for key, group in df.groupby('dup_key'):\n",
    "        status = group['dup_status'].iloc[0]\n",
    "        if status == 'bulk_order':\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "        elif status == 'error':\n",
    "            cleaned = pd.concat([cleaned, group.head(1)])\n",
    "        elif status == 'uncertain':\n",
    "            group['flag_for_review'] = True\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "    return cleaned.reset_index(drop=True)\n",
    "\n",
    "df = handle_duplicates(df)\n",
    "print(\"üîÅ Smart duplicate handling applied (bulk, error, uncertain).\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Q9: Detect and Fix Outlier Prices (Optimized Version)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Step 1: Compute IQR bounds (fallback rule)\n",
    "Q1 = df['original_price_inr'].quantile(0.25)\n",
    "Q3 = df['original_price_inr'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "\n",
    "# Step 2: Define logical price ranges by subcategory\n",
    "subcategory_price_ranges = {\n",
    "    'smartphones': (5000, 100000),\n",
    "    'smart_watch': (500, 15000),\n",
    "    'audio': (300, 20000),\n",
    "    'tablets': (5000, 60000),\n",
    "    'laptops': (20000, 150000),\n",
    "    'tv_&_entertainment': (10000, 150000),\n",
    "    'home_appliances': (2000, 80000),\n",
    "    'accessories': (100, 10000)\n",
    "}\n",
    "\n",
    "# Step 3: Correction function\n",
    "def correct_price(row):\n",
    "    price = row['original_price_inr']\n",
    "    if pd.isna(price):\n",
    "        return price  # skip NaN\n",
    "    \n",
    "    subcat = str(row.get('subcategory', '')).strip().lower().replace(' ', '_')\n",
    "    expected = subcategory_price_ranges.get(subcat)\n",
    "    \n",
    "    # Rule 1: Subcategory-based correction\n",
    "    if expected:\n",
    "        min_p, max_p = expected\n",
    "        if price > max_p * 10:      # unusually high\n",
    "            return price / 100\n",
    "        elif price < min_p / 10:    # unusually low\n",
    "            return price * 100\n",
    "    \n",
    "    # Rule 2: Generic statistical correction\n",
    "    if price > upper_bound * 50:   # extreme high outlier (e.g., 100x mistake)\n",
    "        return price / 100\n",
    "    elif price < lower_bound / 50: # extreme low outlier\n",
    "        return price * 100\n",
    "    \n",
    "    return price\n",
    "\n",
    "# Step 4: Apply the correction efficiently\n",
    "df['original_price_inr'] = df.apply(correct_price, axis=1)\n",
    "\n",
    "print(\"üìà Outlier prices detected and corrected using statistical + category rules.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Q10: Standardize Payment Methods\n",
    "# ----------------------------------------\n",
    "df[\"payment_method\"] = df[\"payment_method\"].astype(str).str.lower().replace({\n",
    "    \"upi\": \"UPI\",\n",
    "    \"phonepe\": \"UPI\",\n",
    "    \"googlepay\": \"UPI\",\n",
    "    \"credit_card\": \"Credit Card\",\n",
    "    \"cc\": \"Credit Card\",\n",
    "    \"debit_card\": \"Debit Card\",\n",
    "    \"cod\": \"Cash On Delivery\",\n",
    "    \"c.o.d\": \"Cash On Delivery\"\n",
    "})\n",
    "print(\"üí≥ Payment methods standardized.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# üßÆ Handle Missing Values (Age, Festival, Delivery)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def convert_age_group(value):\n",
    "    \"\"\"\n",
    "    Convert age range formats like '18-25', '26-35', '55+' into numeric averages.\n",
    "    Handle blanks and unknowns as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"unknown\", \"na\", \"n/a\", \"none\", \"\", \"missing\"]:\n",
    "        return np.nan\n",
    "    if '-' in value:\n",
    "        parts = value.replace('years', '').split('-')\n",
    "        nums = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(nums) if nums else np.nan\n",
    "    if '+' in value:\n",
    "        num = value.replace('+', '').replace('years', '').strip()\n",
    "        if num.isdigit():\n",
    "            return float(num) + 5  # assume midpoint\n",
    "        return np.nan\n",
    "    if value.replace('.', '', 1).isdigit():\n",
    "        return float(value)\n",
    "    return np.nan\n",
    "\n",
    "# Apply to age column\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].apply(convert_age_group)\n",
    "avg_age = round(df[\"customer_age_group\"].mean())\n",
    "df[\"customer_age_group\"].fillna(avg_age, inplace=True)\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].astype(int)\n",
    "print(f\"üë§ Age column cleaned. Missing and unknown values filled with average: {avg_age}\")\n",
    "\n",
    "# Festival name fill\n",
    "df[\"festival_name\"].fillna(\"Unknown\", inplace=True)\n",
    "print(\"üéâ Festival names missing values filled with 'Unknown'.\")\n",
    "\n",
    "# Delivery charges fill\n",
    "df[\"delivery_charges\"].fillna(0, inplace=True)\n",
    "print(\"üí∞ Delivery charges missing values replaced with 0.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# ‚úÖ Final Checks & Save Cleaned Dataset\n",
    "# ----------------------------------------\n",
    "df.info()\n",
    "\n",
    "output_path = r\"C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2021_cleaned.csv\"\n",
    "\n",
    "# ‚úÖ Ensure output folder exists before saving\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "print(\"‚úÖ Data Cleaning Completed & Saved Successfully:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acddf62",
   "metadata": {},
   "source": [
    "### 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0deca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded: (132660, 34)\n",
      "üóìÔ∏è Date column cleaned.\n",
      "üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\n",
      "üí∞ Price columns cleaned and converted to numeric.\n",
      "‚≠ê Ratings standardized to numeric scale.\n",
      "üèôÔ∏è City names standardized.\n",
      "üîò Boolean columns standardized to True/False.\n",
      "üõí Product categories standardized.\n",
      "üöö Delivery days cleaned and standardized.\n",
      "üîÅ Smart duplicate handling applied (bulk, error, uncertain).\n",
      "üìà Outlier prices detected and corrected using statistical + category rules.\n",
      "üí≥ Payment methods standardized.\n",
      "üë§ Age column cleaned. Missing and unknown values filled with average: 32\n",
      "üéâ Festival names missing values filled with 'Unknown'.\n",
      "üí∞ Delivery charges missing values replaced with 0.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 132652 entries, 0 to 132651\n",
      "Data columns (total 38 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   transaction_id          132652 non-null  object \n",
      " 1   order_date              132652 non-null  object \n",
      " 2   customer_id             132652 non-null  object \n",
      " 3   product_id              132652 non-null  object \n",
      " 4   product_name            132652 non-null  object \n",
      " 5   category                132652 non-null  object \n",
      " 6   subcategory             132652 non-null  object \n",
      " 7   brand                   132652 non-null  object \n",
      " 8   original_price_inr      128677 non-null  float64\n",
      " 9   discount_percent        132652 non-null  float64\n",
      " 10  discounted_price_inr    132652 non-null  float64\n",
      " 11  quantity                132652 non-null  int64  \n",
      " 12  subtotal_inr            132652 non-null  float64\n",
      " 13  delivery_charges        132652 non-null  float64\n",
      " 14  final_amount_inr        132652 non-null  float64\n",
      " 15  customer_city           132652 non-null  object \n",
      " 16  customer_state          132652 non-null  object \n",
      " 17  customer_tier           132652 non-null  object \n",
      " 18  customer_spending_tier  132652 non-null  object \n",
      " 19  customer_age_group      132652 non-null  int64  \n",
      " 20  payment_method          132652 non-null  object \n",
      " 21  delivery_days           132652 non-null  float64\n",
      " 22  delivery_type           132652 non-null  object \n",
      " 23  is_prime_member         132652 non-null  bool   \n",
      " 24  is_festival_sale        132652 non-null  bool   \n",
      " 25  festival_name           132652 non-null  object \n",
      " 26  customer_rating         132652 non-null  float64\n",
      " 27  return_status           132652 non-null  object \n",
      " 28  order_month             132652 non-null  int64  \n",
      " 29  order_year              132652 non-null  int64  \n",
      " 30  order_quarter           132652 non-null  int64  \n",
      " 31  product_weight_kg       132652 non-null  float64\n",
      " 32  is_prime_eligible       132652 non-null  bool   \n",
      " 33  product_rating          132652 non-null  float64\n",
      " 34  dup_key                 132652 non-null  object \n",
      " 35  dup_count               132652 non-null  int64  \n",
      " 36  dup_status              132000 non-null  object \n",
      " 37  flag_for_review         131992 non-null  object \n",
      "dtypes: bool(3), float64(10), int64(6), object(19)\n",
      "memory usage: 35.8+ MB\n",
      "‚úÖ Data Cleaning Completed & Saved Successfully: C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2022_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# üßπ Amazon India Data Cleaning \n",
    "# Author: Desikan\n",
    "# Project: Amazon India 10-Year Sales Analytics\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # hide pandas 3.0 warnings\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# ----------------------------------------\n",
    "file_path = r\"C:\\Users\\desik\\Downloads\\Amazon raw dataset\\amazon_india_2022.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"‚úÖ Dataset Loaded:\", df.shape)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3Ô∏è‚É£ Q1: Clean and Standardize Dates\n",
    "# ----------------------------------------\n",
    "def clean_date(date_input):\n",
    "    try:\n",
    "        parsed_date = parser.parse(str(date_input), dayfirst=True)\n",
    "        return parsed_date.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"order_date\"] = df[\"order_date\"].apply(clean_date)\n",
    "print(\"üóìÔ∏è Date column cleaned.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4Ô∏è‚É£ Q2: Clean and Standardize Price Columns (Improved Version)\n",
    "# ----------------------------------------\n",
    "import re\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_price(value):\n",
    "    try:\n",
    "        value = str(value).strip()\n",
    "        # Remove currency symbols and unwanted characters\n",
    "        value = re.sub(r'[‚ÇπRs√¢‚Äö¬π]', '', value, flags=re.IGNORECASE)\n",
    "        value = value.replace(',', '')\n",
    "        \n",
    "        # Handle text like 'Price on Request' or blanks\n",
    "        if not re.match(r'^-?\\d+(\\.\\d+)?$', value):\n",
    "            return pd.NA\n",
    "        \n",
    "        # Convert to float and make sure negatives are positive\n",
    "        return abs(float(value))\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply cleaning to all relevant columns\n",
    "price_cols = [\"original_price_inr\", \"discounted_price_inr\", \"final_amount_inr\", \"delivery_charges\"]\n",
    "\n",
    "for col in price_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_price)\n",
    "\n",
    "print(\"üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\")\n",
    "\n",
    "print(\"üí∞ Price columns cleaned and converted to numeric.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5Ô∏è‚É£ Q3: Standardize Ratings (1.0 - 5.0)\n",
    "# ----------------------------------------\n",
    "def clean_rating(value):\n",
    "    try:\n",
    "        val = str(value).lower().replace(\"stars\", \"\").replace(\"/5\", \"\").replace(\"/5.0\", \"\").strip()\n",
    "        return float(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].apply(clean_rating)\n",
    "df[\"product_rating\"] = df[\"product_rating\"].apply(clean_rating)\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].fillna(df[\"customer_rating\"].median())\n",
    "print(\"‚≠ê Ratings standardized to numeric scale.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6Ô∏è‚É£ Q4: Standardize City Names\n",
    "# ----------------------------------------\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype(str).str.title().str.strip()\n",
    "city_mapping = {\n",
    "    'ahmedabad': 'Ahmedabad',\n",
    "    'aligarh': 'Aligarh',\n",
    "    'allahabad': 'Allahabad',\n",
    "    'bangalore': 'Bengaluru',\n",
    "    'banglore': 'Bengaluru',\n",
    "    'bengalore': 'Bengaluru',\n",
    "    'bengaluru': 'Bengaluru',\n",
    "    'bhubaneswar': 'Bhubaneswar',\n",
    "    'bombay': 'Mumbai',\n",
    "    'calcutta': 'Kolkata',\n",
    "    'chandigarh': 'Chandigarh',\n",
    "    'chenai': 'Chennai',\n",
    "    'chennai': 'Chennai',\n",
    "    'coimbatore': 'Coimbatore',\n",
    "    'customer_city': 'Unknown',\n",
    "    'delhi': 'Delhi',\n",
    "    'delhi ncr': 'Delhi',\n",
    "    'new delhi': 'Delhi',\n",
    "    'gorakhpur': 'Gorakhpur',\n",
    "    'hyderabad': 'Hyderabad',\n",
    "    'indore': 'Indore',\n",
    "    'jaipur': 'Jaipur',\n",
    "    'kanpur': 'Kanpur',\n",
    "    'kochi': 'Kochi',\n",
    "    'kolkata': 'Kolkata',\n",
    "    'lucknow': 'Lucknow',\n",
    "    'ludhiana': 'Ludhiana',\n",
    "    'madras': 'Chennai',\n",
    "    'meerut': 'Meerut',\n",
    "    'moradabad': 'Moradabad',\n",
    "    'mumba': 'Mumbai',\n",
    "    'mumbai': 'Mumbai',\n",
    "    'nagpur': 'Nagpur',\n",
    "    'patna': 'Patna',\n",
    "    'pune': 'Pune',\n",
    "    'saharanpur': 'Saharanpur',\n",
    "    'surat': 'Surat',\n",
    "    'vadodara': 'Vadodara',\n",
    "    'varanasi': 'Varanasi',\n",
    "    'visakhapatnam': 'Visakhapatnam'\n",
    "}\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(city_mapping)\n",
    "print(\"üèôÔ∏è City names standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7Ô∏è‚É£ Q5: Clean Boolean Columns\n",
    "# ----------------------------------------\n",
    "bool_cols = [\"is_prime_member\", \"is_prime_eligible\", \"is_festival_sale\"]\n",
    "\n",
    "for col in bool_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .replace({\n",
    "            \"yes\": True, \"true\": True, \"1\": True, \"y\": True,\n",
    "            \"no\": False, \"false\": False, \"0\": False, \"n\": False\n",
    "        })\n",
    "    )\n",
    "    df[col] = df[col].astype(bool)\n",
    "\n",
    "print(\"üîò Boolean columns standardized to True/False.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 8Ô∏è‚É£ Q6: Standardize Product Categories\n",
    "# ----------------------------------------\n",
    "df[\"category\"] = df[\"category\"].astype(str).str.title().str.strip()\n",
    "category_mapping = {\n",
    "    'electronics': 'Electronics',\n",
    "    'electronic': 'Electronics',\n",
    "    'electronics & accessories': 'Electronics',\n",
    "    'electronicss': 'Electronics'\n",
    "}\n",
    "df[\"category\"] = df[\"category\"].replace(category_mapping)\n",
    "print(\"üõí Product categories standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 9Ô∏è‚É£ Q7: Clean Delivery Days\n",
    "# ----------------------------------------\n",
    "def clean_delivery_days(x):\n",
    "    x = str(x).lower()\n",
    "    if \"same\" in x:\n",
    "        return 0\n",
    "    elif \"-\" in x:\n",
    "        parts = x.replace(\"days\", \"\").split(\"-\")\n",
    "        parts = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(parts) if parts else np.nan\n",
    "    elif x.replace('.', '', 1).isdigit():\n",
    "        return float(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].apply(clean_delivery_days)\n",
    "df.loc[df[\"delivery_days\"] < 0, \"delivery_days\"] = np.nan\n",
    "df.loc[df[\"delivery_days\"] > 30, \"delivery_days\"] = np.nan\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].fillna(df[\"delivery_days\"].median())\n",
    "print(\"üöö Delivery days cleaned and standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# üîü Q8: Handle Duplicate Transactions\n",
    "# ----------------------------------------\n",
    "# Create composite key\n",
    "df['dup_key'] = df[['customer_id', 'product_id', 'order_date', 'final_amount_inr']].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# Count occurrences\n",
    "dup_counts = df['dup_key'].value_counts().to_dict()\n",
    "df['dup_count'] = df['dup_key'].map(dup_counts)\n",
    "\n",
    "def is_same_timestamp(group):\n",
    "    return group['order_date'].nunique() == 1\n",
    "\n",
    "def classify_group(group):\n",
    "    if group['dup_count'].iloc[0] > 3 and not is_same_timestamp(group):\n",
    "        return 'bulk_order'\n",
    "    elif is_same_timestamp(group) and group['dup_count'].iloc[0] > 1:\n",
    "        return 'error'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "df['dup_status'] = df.groupby('dup_key').apply(classify_group).reset_index(drop=True)\n",
    "\n",
    "def handle_duplicates(df):\n",
    "    cleaned = pd.DataFrame()\n",
    "    for key, group in df.groupby('dup_key'):\n",
    "        status = group['dup_status'].iloc[0]\n",
    "        if status == 'bulk_order':\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "        elif status == 'error':\n",
    "            cleaned = pd.concat([cleaned, group.head(1)])\n",
    "        elif status == 'uncertain':\n",
    "            group['flag_for_review'] = True\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "    return cleaned.reset_index(drop=True)\n",
    "\n",
    "df = handle_duplicates(df)\n",
    "print(\"üîÅ Smart duplicate handling applied (bulk, error, uncertain).\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Q9: Detect and Fix Outlier Prices (Optimized Version)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Step 1: Compute IQR bounds (fallback rule)\n",
    "Q1 = df['original_price_inr'].quantile(0.25)\n",
    "Q3 = df['original_price_inr'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "\n",
    "# Step 2: Define logical price ranges by subcategory\n",
    "subcategory_price_ranges = {\n",
    "    'smartphones': (5000, 100000),\n",
    "    'smart_watch': (500, 15000),\n",
    "    'audio': (300, 20000),\n",
    "    'tablets': (5000, 60000),\n",
    "    'laptops': (20000, 150000),\n",
    "    'tv_&_entertainment': (10000, 150000),\n",
    "    'home_appliances': (2000, 80000),\n",
    "    'accessories': (100, 10000)\n",
    "}\n",
    "\n",
    "# Step 3: Correction function\n",
    "def correct_price(row):\n",
    "    price = row['original_price_inr']\n",
    "    if pd.isna(price):\n",
    "        return price  # skip NaN\n",
    "    \n",
    "    subcat = str(row.get('subcategory', '')).strip().lower().replace(' ', '_')\n",
    "    expected = subcategory_price_ranges.get(subcat)\n",
    "    \n",
    "    # Rule 1: Subcategory-based correction\n",
    "    if expected:\n",
    "        min_p, max_p = expected\n",
    "        if price > max_p * 10:      # unusually high\n",
    "            return price / 100\n",
    "        elif price < min_p / 10:    # unusually low\n",
    "            return price * 100\n",
    "    \n",
    "    # Rule 2: Generic statistical correction\n",
    "    if price > upper_bound * 50:   # extreme high outlier (e.g., 100x mistake)\n",
    "        return price / 100\n",
    "    elif price < lower_bound / 50: # extreme low outlier\n",
    "        return price * 100\n",
    "    \n",
    "    return price\n",
    "\n",
    "# Step 4: Apply the correction efficiently\n",
    "df['original_price_inr'] = df.apply(correct_price, axis=1)\n",
    "\n",
    "print(\"üìà Outlier prices detected and corrected using statistical + category rules.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Q10: Standardize Payment Methods\n",
    "# ----------------------------------------\n",
    "df[\"payment_method\"] = df[\"payment_method\"].astype(str).str.lower().replace({\n",
    "    \"upi\": \"UPI\",\n",
    "    \"phonepe\": \"UPI\",\n",
    "    \"googlepay\": \"UPI\",\n",
    "    \"credit_card\": \"Credit Card\",\n",
    "    \"cc\": \"Credit Card\",\n",
    "    \"debit_card\": \"Debit Card\",\n",
    "    \"cod\": \"Cash On Delivery\",\n",
    "    \"c.o.d\": \"Cash On Delivery\"\n",
    "})\n",
    "print(\"üí≥ Payment methods standardized.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# üßÆ Handle Missing Values (Age, Festival, Delivery)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def convert_age_group(value):\n",
    "    \"\"\"\n",
    "    Convert age range formats like '18-25', '26-35', '55+' into numeric averages.\n",
    "    Handle blanks and unknowns as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"unknown\", \"na\", \"n/a\", \"none\", \"\", \"missing\"]:\n",
    "        return np.nan\n",
    "    if '-' in value:\n",
    "        parts = value.replace('years', '').split('-')\n",
    "        nums = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(nums) if nums else np.nan\n",
    "    if '+' in value:\n",
    "        num = value.replace('+', '').replace('years', '').strip()\n",
    "        if num.isdigit():\n",
    "            return float(num) + 5  # assume midpoint\n",
    "        return np.nan\n",
    "    if value.replace('.', '', 1).isdigit():\n",
    "        return float(value)\n",
    "    return np.nan\n",
    "\n",
    "# Apply to age column\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].apply(convert_age_group)\n",
    "avg_age = round(df[\"customer_age_group\"].mean())\n",
    "df[\"customer_age_group\"].fillna(avg_age, inplace=True)\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].astype(int)\n",
    "print(f\"üë§ Age column cleaned. Missing and unknown values filled with average: {avg_age}\")\n",
    "\n",
    "# Festival name fill\n",
    "df[\"festival_name\"].fillna(\"Unknown\", inplace=True)\n",
    "print(\"üéâ Festival names missing values filled with 'Unknown'.\")\n",
    "\n",
    "# Delivery charges fill\n",
    "df[\"delivery_charges\"].fillna(0, inplace=True)\n",
    "print(\"üí∞ Delivery charges missing values replaced with 0.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# ‚úÖ Final Checks & Save Cleaned Dataset\n",
    "# ----------------------------------------\n",
    "df.info()\n",
    "\n",
    "output_path = r\"C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2022_cleaned.csv\"\n",
    "\n",
    "# ‚úÖ Ensure output folder exists before saving\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "print(\"‚úÖ Data Cleaning Completed & Saved Successfully:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49643b",
   "metadata": {},
   "source": [
    "### 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab7dc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded: (127132, 34)\n",
      "üóìÔ∏è Date column cleaned.\n",
      "üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\n",
      "üí∞ Price columns cleaned and converted to numeric.\n",
      "‚≠ê Ratings standardized to numeric scale.\n",
      "üèôÔ∏è City names standardized.\n",
      "üîò Boolean columns standardized to True/False.\n",
      "üõí Product categories standardized.\n",
      "üöö Delivery days cleaned and standardized.\n",
      "üîÅ Smart duplicate handling applied (bulk, error, uncertain).\n",
      "üìà Outlier prices detected and corrected using statistical + category rules.\n",
      "üí≥ Payment methods standardized.\n",
      "üë§ Age column cleaned. Missing and unknown values filled with average: 33\n",
      "üéâ Festival names missing values filled with 'Unknown'.\n",
      "üí∞ Delivery charges missing values replaced with 0.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127130 entries, 0 to 127129\n",
      "Data columns (total 38 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   transaction_id          127130 non-null  object \n",
      " 1   order_date              127130 non-null  object \n",
      " 2   customer_id             127130 non-null  object \n",
      " 3   product_id              127130 non-null  object \n",
      " 4   product_name            127130 non-null  object \n",
      " 5   category                127130 non-null  object \n",
      " 6   subcategory             127130 non-null  object \n",
      " 7   brand                   127130 non-null  object \n",
      " 8   original_price_inr      123345 non-null  float64\n",
      " 9   discount_percent        127130 non-null  float64\n",
      " 10  discounted_price_inr    127130 non-null  float64\n",
      " 11  quantity                127130 non-null  int64  \n",
      " 12  subtotal_inr            127130 non-null  float64\n",
      " 13  delivery_charges        127130 non-null  float64\n",
      " 14  final_amount_inr        127130 non-null  float64\n",
      " 15  customer_city           127130 non-null  object \n",
      " 16  customer_state          127130 non-null  object \n",
      " 17  customer_tier           127130 non-null  object \n",
      " 18  customer_spending_tier  127130 non-null  object \n",
      " 19  customer_age_group      127130 non-null  int64  \n",
      " 20  payment_method          127130 non-null  object \n",
      " 21  delivery_days           127130 non-null  float64\n",
      " 22  delivery_type           127130 non-null  object \n",
      " 23  is_prime_member         127130 non-null  bool   \n",
      " 24  is_festival_sale        127130 non-null  bool   \n",
      " 25  festival_name           127130 non-null  object \n",
      " 26  customer_rating         127130 non-null  float64\n",
      " 27  return_status           127130 non-null  object \n",
      " 28  order_month             127130 non-null  int64  \n",
      " 29  order_year              127130 non-null  int64  \n",
      " 30  order_quarter           127130 non-null  int64  \n",
      " 31  product_weight_kg       127130 non-null  float64\n",
      " 32  is_prime_eligible       127130 non-null  bool   \n",
      " 33  product_rating          127130 non-null  float64\n",
      " 34  dup_key                 127130 non-null  object \n",
      " 35  dup_count               127130 non-null  int64  \n",
      " 36  dup_status              126500 non-null  object \n",
      " 37  flag_for_review         126498 non-null  object \n",
      "dtypes: bool(3), float64(10), int64(6), object(19)\n",
      "memory usage: 34.3+ MB\n",
      "‚úÖ Data Cleaning Completed & Saved Successfully: C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2023_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# üßπ Amazon India Data Cleaning \n",
    "# Author: Desikan\n",
    "# Project: Amazon India 10-Year Sales Analytics\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # hide pandas 3.0 warnings\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# ----------------------------------------\n",
    "file_path = r\"C:\\Users\\desik\\Downloads\\Amazon raw dataset\\amazon_india_2023.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"‚úÖ Dataset Loaded:\", df.shape)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3Ô∏è‚É£ Q1: Clean and Standardize Dates\n",
    "# ----------------------------------------\n",
    "def clean_date(date_input):\n",
    "    try:\n",
    "        parsed_date = parser.parse(str(date_input), dayfirst=True)\n",
    "        return parsed_date.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"order_date\"] = df[\"order_date\"].apply(clean_date)\n",
    "print(\"üóìÔ∏è Date column cleaned.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4Ô∏è‚É£ Q2: Clean and Standardize Price Columns (Improved Version)\n",
    "# ----------------------------------------\n",
    "import re\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_price(value):\n",
    "    try:\n",
    "        value = str(value).strip()\n",
    "        # Remove currency symbols and unwanted characters\n",
    "        value = re.sub(r'[‚ÇπRs√¢‚Äö¬π]', '', value, flags=re.IGNORECASE)\n",
    "        value = value.replace(',', '')\n",
    "        \n",
    "        # Handle text like 'Price on Request' or blanks\n",
    "        if not re.match(r'^-?\\d+(\\.\\d+)?$', value):\n",
    "            return pd.NA\n",
    "        \n",
    "        # Convert to float and make sure negatives are positive\n",
    "        return abs(float(value))\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply cleaning to all relevant columns\n",
    "price_cols = [\"original_price_inr\", \"discounted_price_inr\", \"final_amount_inr\", \"delivery_charges\"]\n",
    "\n",
    "for col in price_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_price)\n",
    "\n",
    "print(\"üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\")\n",
    "\n",
    "print(\"üí∞ Price columns cleaned and converted to numeric.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5Ô∏è‚É£ Q3: Standardize Ratings (1.0 - 5.0)\n",
    "# ----------------------------------------\n",
    "def clean_rating(value):\n",
    "    try:\n",
    "        val = str(value).lower().replace(\"stars\", \"\").replace(\"/5\", \"\").replace(\"/5.0\", \"\").strip()\n",
    "        return float(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].apply(clean_rating)\n",
    "df[\"product_rating\"] = df[\"product_rating\"].apply(clean_rating)\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].fillna(df[\"customer_rating\"].median())\n",
    "print(\"‚≠ê Ratings standardized to numeric scale.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6Ô∏è‚É£ Q4: Standardize City Names\n",
    "# ----------------------------------------\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype(str).str.title().str.strip()\n",
    "city_mapping = {\n",
    "    'ahmedabad': 'Ahmedabad',\n",
    "    'aligarh': 'Aligarh',\n",
    "    'allahabad': 'Allahabad',\n",
    "    'bangalore': 'Bengaluru',\n",
    "    'banglore': 'Bengaluru',\n",
    "    'bengalore': 'Bengaluru',\n",
    "    'bengaluru': 'Bengaluru',\n",
    "    'bhubaneswar': 'Bhubaneswar',\n",
    "    'bombay': 'Mumbai',\n",
    "    'calcutta': 'Kolkata',\n",
    "    'chandigarh': 'Chandigarh',\n",
    "    'chenai': 'Chennai',\n",
    "    'chennai': 'Chennai',\n",
    "    'coimbatore': 'Coimbatore',\n",
    "    'customer_city': 'Unknown',\n",
    "    'delhi': 'Delhi',\n",
    "    'delhi ncr': 'Delhi',\n",
    "    'new delhi': 'Delhi',\n",
    "    'gorakhpur': 'Gorakhpur',\n",
    "    'hyderabad': 'Hyderabad',\n",
    "    'indore': 'Indore',\n",
    "    'jaipur': 'Jaipur',\n",
    "    'kanpur': 'Kanpur',\n",
    "    'kochi': 'Kochi',\n",
    "    'kolkata': 'Kolkata',\n",
    "    'lucknow': 'Lucknow',\n",
    "    'ludhiana': 'Ludhiana',\n",
    "    'madras': 'Chennai',\n",
    "    'meerut': 'Meerut',\n",
    "    'moradabad': 'Moradabad',\n",
    "    'mumba': 'Mumbai',\n",
    "    'mumbai': 'Mumbai',\n",
    "    'nagpur': 'Nagpur',\n",
    "    'patna': 'Patna',\n",
    "    'pune': 'Pune',\n",
    "    'saharanpur': 'Saharanpur',\n",
    "    'surat': 'Surat',\n",
    "    'vadodara': 'Vadodara',\n",
    "    'varanasi': 'Varanasi',\n",
    "    'visakhapatnam': 'Visakhapatnam'\n",
    "}\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(city_mapping)\n",
    "print(\"üèôÔ∏è City names standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7Ô∏è‚É£ Q5: Clean Boolean Columns\n",
    "# ----------------------------------------\n",
    "bool_cols = [\"is_prime_member\", \"is_prime_eligible\", \"is_festival_sale\"]\n",
    "\n",
    "for col in bool_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .replace({\n",
    "            \"yes\": True, \"true\": True, \"1\": True, \"y\": True,\n",
    "            \"no\": False, \"false\": False, \"0\": False, \"n\": False\n",
    "        })\n",
    "    )\n",
    "    df[col] = df[col].astype(bool)\n",
    "\n",
    "print(\"üîò Boolean columns standardized to True/False.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 8Ô∏è‚É£ Q6: Standardize Product Categories\n",
    "# ----------------------------------------\n",
    "df[\"category\"] = df[\"category\"].astype(str).str.title().str.strip()\n",
    "category_mapping = {\n",
    "    'electronics': 'Electronics',\n",
    "    'electronic': 'Electronics',\n",
    "    'electronics & accessories': 'Electronics',\n",
    "    'electronicss': 'Electronics'\n",
    "}\n",
    "df[\"category\"] = df[\"category\"].replace(category_mapping)\n",
    "print(\"üõí Product categories standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 9Ô∏è‚É£ Q7: Clean Delivery Days\n",
    "# ----------------------------------------\n",
    "def clean_delivery_days(x):\n",
    "    x = str(x).lower()\n",
    "    if \"same\" in x:\n",
    "        return 0\n",
    "    elif \"-\" in x:\n",
    "        parts = x.replace(\"days\", \"\").split(\"-\")\n",
    "        parts = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(parts) if parts else np.nan\n",
    "    elif x.replace('.', '', 1).isdigit():\n",
    "        return float(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].apply(clean_delivery_days)\n",
    "df.loc[df[\"delivery_days\"] < 0, \"delivery_days\"] = np.nan\n",
    "df.loc[df[\"delivery_days\"] > 30, \"delivery_days\"] = np.nan\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].fillna(df[\"delivery_days\"].median())\n",
    "print(\"üöö Delivery days cleaned and standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# üîü Q8: Handle Duplicate Transactions\n",
    "# ----------------------------------------\n",
    "# Create composite key\n",
    "df['dup_key'] = df[['customer_id', 'product_id', 'order_date', 'final_amount_inr']].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# Count occurrences\n",
    "dup_counts = df['dup_key'].value_counts().to_dict()\n",
    "df['dup_count'] = df['dup_key'].map(dup_counts)\n",
    "\n",
    "def is_same_timestamp(group):\n",
    "    return group['order_date'].nunique() == 1\n",
    "\n",
    "def classify_group(group):\n",
    "    if group['dup_count'].iloc[0] > 3 and not is_same_timestamp(group):\n",
    "        return 'bulk_order'\n",
    "    elif is_same_timestamp(group) and group['dup_count'].iloc[0] > 1:\n",
    "        return 'error'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "df['dup_status'] = df.groupby('dup_key').apply(classify_group).reset_index(drop=True)\n",
    "\n",
    "def handle_duplicates(df):\n",
    "    cleaned = pd.DataFrame()\n",
    "    for key, group in df.groupby('dup_key'):\n",
    "        status = group['dup_status'].iloc[0]\n",
    "        if status == 'bulk_order':\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "        elif status == 'error':\n",
    "            cleaned = pd.concat([cleaned, group.head(1)])\n",
    "        elif status == 'uncertain':\n",
    "            group['flag_for_review'] = True\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "    return cleaned.reset_index(drop=True)\n",
    "\n",
    "df = handle_duplicates(df)\n",
    "print(\"üîÅ Smart duplicate handling applied (bulk, error, uncertain).\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Q9: Detect and Fix Outlier Prices (Optimized Version)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Step 1: Compute IQR bounds (fallback rule)\n",
    "Q1 = df['original_price_inr'].quantile(0.25)\n",
    "Q3 = df['original_price_inr'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "\n",
    "# Step 2: Define logical price ranges by subcategory\n",
    "subcategory_price_ranges = {\n",
    "    'smartphones': (5000, 100000),\n",
    "    'smart_watch': (500, 15000),\n",
    "    'audio': (300, 20000),\n",
    "    'tablets': (5000, 60000),\n",
    "    'laptops': (20000, 150000),\n",
    "    'tv_&_entertainment': (10000, 150000),\n",
    "    'home_appliances': (2000, 80000),\n",
    "    'accessories': (100, 10000)\n",
    "}\n",
    "\n",
    "# Step 3: Correction function\n",
    "def correct_price(row):\n",
    "    price = row['original_price_inr']\n",
    "    if pd.isna(price):\n",
    "        return price  # skip NaN\n",
    "    \n",
    "    subcat = str(row.get('subcategory', '')).strip().lower().replace(' ', '_')\n",
    "    expected = subcategory_price_ranges.get(subcat)\n",
    "    \n",
    "    # Rule 1: Subcategory-based correction\n",
    "    if expected:\n",
    "        min_p, max_p = expected\n",
    "        if price > max_p * 10:      # unusually high\n",
    "            return price / 100\n",
    "        elif price < min_p / 10:    # unusually low\n",
    "            return price * 100\n",
    "    \n",
    "    # Rule 2: Generic statistical correction\n",
    "    if price > upper_bound * 50:   # extreme high outlier (e.g., 100x mistake)\n",
    "        return price / 100\n",
    "    elif price < lower_bound / 50: # extreme low outlier\n",
    "        return price * 100\n",
    "    \n",
    "    return price\n",
    "\n",
    "# Step 4: Apply the correction efficiently\n",
    "df['original_price_inr'] = df.apply(correct_price, axis=1)\n",
    "\n",
    "print(\"üìà Outlier prices detected and corrected using statistical + category rules.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Q10: Standardize Payment Methods\n",
    "# ----------------------------------------\n",
    "df[\"payment_method\"] = df[\"payment_method\"].astype(str).str.lower().replace({\n",
    "    \"upi\": \"UPI\",\n",
    "    \"phonepe\": \"UPI\",\n",
    "    \"googlepay\": \"UPI\",\n",
    "    \"credit_card\": \"Credit Card\",\n",
    "    \"cc\": \"Credit Card\",\n",
    "    \"debit_card\": \"Debit Card\",\n",
    "    \"cod\": \"Cash On Delivery\",\n",
    "    \"c.o.d\": \"Cash On Delivery\"\n",
    "})\n",
    "print(\"üí≥ Payment methods standardized.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# üßÆ Handle Missing Values (Age, Festival, Delivery)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def convert_age_group(value):\n",
    "    \"\"\"\n",
    "    Convert age range formats like '18-25', '26-35', '55+' into numeric averages.\n",
    "    Handle blanks and unknowns as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"unknown\", \"na\", \"n/a\", \"none\", \"\", \"missing\"]:\n",
    "        return np.nan\n",
    "    if '-' in value:\n",
    "        parts = value.replace('years', '').split('-')\n",
    "        nums = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(nums) if nums else np.nan\n",
    "    if '+' in value:\n",
    "        num = value.replace('+', '').replace('years', '').strip()\n",
    "        if num.isdigit():\n",
    "            return float(num) + 5  # assume midpoint\n",
    "        return np.nan\n",
    "    if value.replace('.', '', 1).isdigit():\n",
    "        return float(value)\n",
    "    return np.nan\n",
    "\n",
    "# Apply to age column\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].apply(convert_age_group)\n",
    "avg_age = round(df[\"customer_age_group\"].mean())\n",
    "df[\"customer_age_group\"].fillna(avg_age, inplace=True)\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].astype(int)\n",
    "print(f\"üë§ Age column cleaned. Missing and unknown values filled with average: {avg_age}\")\n",
    "\n",
    "# Festival name fill\n",
    "df[\"festival_name\"].fillna(\"Unknown\", inplace=True)\n",
    "print(\"üéâ Festival names missing values filled with 'Unknown'.\")\n",
    "\n",
    "# Delivery charges fill\n",
    "df[\"delivery_charges\"].fillna(0, inplace=True)\n",
    "print(\"üí∞ Delivery charges missing values replaced with 0.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# ‚úÖ Final Checks & Save Cleaned Dataset\n",
    "# ----------------------------------------\n",
    "df.info()\n",
    "\n",
    "output_path = r\"C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2023_cleaned.csv\"\n",
    "\n",
    "# ‚úÖ Ensure output folder exists before saving\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "print(\"‚úÖ Data Cleaning Completed & Saved Successfully:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2807dc67",
   "metadata": {},
   "source": [
    "### 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb81477e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded: (121605, 34)\n",
      "üóìÔ∏è Date column cleaned.\n",
      "üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\n",
      "üí∞ Price columns cleaned and converted to numeric.\n",
      "‚≠ê Ratings standardized to numeric scale.\n",
      "üèôÔ∏è City names standardized.\n",
      "üîò Boolean columns standardized to True/False.\n",
      "üõí Product categories standardized.\n",
      "üöö Delivery days cleaned and standardized.\n",
      "üîÅ Smart duplicate handling applied (bulk, error, uncertain).\n",
      "üìà Outlier prices detected and corrected using statistical + category rules.\n",
      "üí≥ Payment methods standardized.\n",
      "üë§ Age column cleaned. Missing and unknown values filled with average: 33\n",
      "üéâ Festival names missing values filled with 'Unknown'.\n",
      "üí∞ Delivery charges missing values replaced with 0.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121604 entries, 0 to 121603\n",
      "Data columns (total 38 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   transaction_id          121604 non-null  object \n",
      " 1   order_date              121604 non-null  object \n",
      " 2   customer_id             121604 non-null  object \n",
      " 3   product_id              121604 non-null  object \n",
      " 4   product_name            121604 non-null  object \n",
      " 5   category                121604 non-null  object \n",
      " 6   subcategory             121604 non-null  object \n",
      " 7   brand                   121604 non-null  object \n",
      " 8   original_price_inr      117907 non-null  float64\n",
      " 9   discount_percent        121604 non-null  float64\n",
      " 10  discounted_price_inr    121604 non-null  float64\n",
      " 11  quantity                121604 non-null  int64  \n",
      " 12  subtotal_inr            121604 non-null  float64\n",
      " 13  delivery_charges        121604 non-null  float64\n",
      " 14  final_amount_inr        121604 non-null  float64\n",
      " 15  customer_city           121604 non-null  object \n",
      " 16  customer_state          121604 non-null  object \n",
      " 17  customer_tier           121604 non-null  object \n",
      " 18  customer_spending_tier  121604 non-null  object \n",
      " 19  customer_age_group      121604 non-null  int64  \n",
      " 20  payment_method          121604 non-null  object \n",
      " 21  delivery_days           121604 non-null  float64\n",
      " 22  delivery_type           121604 non-null  object \n",
      " 23  is_prime_member         121604 non-null  bool   \n",
      " 24  is_festival_sale        121604 non-null  bool   \n",
      " 25  festival_name           121604 non-null  object \n",
      " 26  customer_rating         121604 non-null  float64\n",
      " 27  return_status           121604 non-null  object \n",
      " 28  order_month             121604 non-null  int64  \n",
      " 29  order_year              121604 non-null  int64  \n",
      " 30  order_quarter           121604 non-null  int64  \n",
      " 31  product_weight_kg       121604 non-null  float64\n",
      " 32  is_prime_eligible       121604 non-null  bool   \n",
      " 33  product_rating          121604 non-null  float64\n",
      " 34  dup_key                 121604 non-null  object \n",
      " 35  dup_count               121604 non-null  int64  \n",
      " 36  dup_status              121000 non-null  object \n",
      " 37  flag_for_review         120999 non-null  object \n",
      "dtypes: bool(3), float64(10), int64(6), object(19)\n",
      "memory usage: 32.8+ MB\n",
      "‚úÖ Data Cleaning Completed & Saved Successfully: C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2024_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# üßπ Amazon India Data Cleaning \n",
    "# Author: Desikan\n",
    "# Project: Amazon India 10-Year Sales Analytics\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # hide pandas 3.0 warnings\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# ----------------------------------------\n",
    "file_path = r\"C:\\Users\\desik\\Downloads\\Amazon raw dataset\\amazon_india_2024.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"‚úÖ Dataset Loaded:\", df.shape)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3Ô∏è‚É£ Q1: Clean and Standardize Dates\n",
    "# ----------------------------------------\n",
    "def clean_date(date_input):\n",
    "    try:\n",
    "        parsed_date = parser.parse(str(date_input), dayfirst=True)\n",
    "        return parsed_date.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"order_date\"] = df[\"order_date\"].apply(clean_date)\n",
    "print(\"üóìÔ∏è Date column cleaned.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4Ô∏è‚É£ Q2: Clean and Standardize Price Columns (Improved Version)\n",
    "# ----------------------------------------\n",
    "import re\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_price(value):\n",
    "    try:\n",
    "        value = str(value).strip()\n",
    "        # Remove currency symbols and unwanted characters\n",
    "        value = re.sub(r'[‚ÇπRs√¢‚Äö¬π]', '', value, flags=re.IGNORECASE)\n",
    "        value = value.replace(',', '')\n",
    "        \n",
    "        # Handle text like 'Price on Request' or blanks\n",
    "        if not re.match(r'^-?\\d+(\\.\\d+)?$', value):\n",
    "            return pd.NA\n",
    "        \n",
    "        # Convert to float and make sure negatives are positive\n",
    "        return abs(float(value))\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply cleaning to all relevant columns\n",
    "price_cols = [\"original_price_inr\", \"discounted_price_inr\", \"final_amount_inr\", \"delivery_charges\"]\n",
    "\n",
    "for col in price_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_price)\n",
    "\n",
    "print(\"üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\")\n",
    "\n",
    "print(\"üí∞ Price columns cleaned and converted to numeric.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5Ô∏è‚É£ Q3: Standardize Ratings (1.0 - 5.0)\n",
    "# ----------------------------------------\n",
    "def clean_rating(value):\n",
    "    try:\n",
    "        val = str(value).lower().replace(\"stars\", \"\").replace(\"/5\", \"\").replace(\"/5.0\", \"\").strip()\n",
    "        return float(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].apply(clean_rating)\n",
    "df[\"product_rating\"] = df[\"product_rating\"].apply(clean_rating)\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].fillna(df[\"customer_rating\"].median())\n",
    "print(\"‚≠ê Ratings standardized to numeric scale.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6Ô∏è‚É£ Q4: Standardize City Names\n",
    "# ----------------------------------------\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype(str).str.title().str.strip()\n",
    "city_mapping = {\n",
    "    'ahmedabad': 'Ahmedabad',\n",
    "    'aligarh': 'Aligarh',\n",
    "    'allahabad': 'Allahabad',\n",
    "    'bangalore': 'Bengaluru',\n",
    "    'banglore': 'Bengaluru',\n",
    "    'bengalore': 'Bengaluru',\n",
    "    'bengaluru': 'Bengaluru',\n",
    "    'bhubaneswar': 'Bhubaneswar',\n",
    "    'bombay': 'Mumbai',\n",
    "    'calcutta': 'Kolkata',\n",
    "    'chandigarh': 'Chandigarh',\n",
    "    'chenai': 'Chennai',\n",
    "    'chennai': 'Chennai',\n",
    "    'coimbatore': 'Coimbatore',\n",
    "    'customer_city': 'Unknown',\n",
    "    'delhi': 'Delhi',\n",
    "    'delhi ncr': 'Delhi',\n",
    "    'new delhi': 'Delhi',\n",
    "    'gorakhpur': 'Gorakhpur',\n",
    "    'hyderabad': 'Hyderabad',\n",
    "    'indore': 'Indore',\n",
    "    'jaipur': 'Jaipur',\n",
    "    'kanpur': 'Kanpur',\n",
    "    'kochi': 'Kochi',\n",
    "    'kolkata': 'Kolkata',\n",
    "    'lucknow': 'Lucknow',\n",
    "    'ludhiana': 'Ludhiana',\n",
    "    'madras': 'Chennai',\n",
    "    'meerut': 'Meerut',\n",
    "    'moradabad': 'Moradabad',\n",
    "    'mumba': 'Mumbai',\n",
    "    'mumbai': 'Mumbai',\n",
    "    'nagpur': 'Nagpur',\n",
    "    'patna': 'Patna',\n",
    "    'pune': 'Pune',\n",
    "    'saharanpur': 'Saharanpur',\n",
    "    'surat': 'Surat',\n",
    "    'vadodara': 'Vadodara',\n",
    "    'varanasi': 'Varanasi',\n",
    "    'visakhapatnam': 'Visakhapatnam'\n",
    "}\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(city_mapping)\n",
    "print(\"üèôÔ∏è City names standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7Ô∏è‚É£ Q5: Clean Boolean Columns\n",
    "# ----------------------------------------\n",
    "bool_cols = [\"is_prime_member\", \"is_prime_eligible\", \"is_festival_sale\"]\n",
    "\n",
    "for col in bool_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .replace({\n",
    "            \"yes\": True, \"true\": True, \"1\": True, \"y\": True,\n",
    "            \"no\": False, \"false\": False, \"0\": False, \"n\": False\n",
    "        })\n",
    "    )\n",
    "    df[col] = df[col].astype(bool)\n",
    "\n",
    "print(\"üîò Boolean columns standardized to True/False.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 8Ô∏è‚É£ Q6: Standardize Product Categories\n",
    "# ----------------------------------------\n",
    "df[\"category\"] = df[\"category\"].astype(str).str.title().str.strip()\n",
    "category_mapping = {\n",
    "    'electronics': 'Electronics',\n",
    "    'electronic': 'Electronics',\n",
    "    'electronics & accessories': 'Electronics',\n",
    "    'electronicss': 'Electronics'\n",
    "}\n",
    "df[\"category\"] = df[\"category\"].replace(category_mapping)\n",
    "print(\"üõí Product categories standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 9Ô∏è‚É£ Q7: Clean Delivery Days\n",
    "# ----------------------------------------\n",
    "def clean_delivery_days(x):\n",
    "    x = str(x).lower()\n",
    "    if \"same\" in x:\n",
    "        return 0\n",
    "    elif \"-\" in x:\n",
    "        parts = x.replace(\"days\", \"\").split(\"-\")\n",
    "        parts = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(parts) if parts else np.nan\n",
    "    elif x.replace('.', '', 1).isdigit():\n",
    "        return float(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].apply(clean_delivery_days)\n",
    "df.loc[df[\"delivery_days\"] < 0, \"delivery_days\"] = np.nan\n",
    "df.loc[df[\"delivery_days\"] > 30, \"delivery_days\"] = np.nan\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].fillna(df[\"delivery_days\"].median())\n",
    "print(\"üöö Delivery days cleaned and standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# üîü Q8: Handle Duplicate Transactions\n",
    "# ----------------------------------------\n",
    "# Create composite key\n",
    "df['dup_key'] = df[['customer_id', 'product_id', 'order_date', 'final_amount_inr']].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# Count occurrences\n",
    "dup_counts = df['dup_key'].value_counts().to_dict()\n",
    "df['dup_count'] = df['dup_key'].map(dup_counts)\n",
    "\n",
    "def is_same_timestamp(group):\n",
    "    return group['order_date'].nunique() == 1\n",
    "\n",
    "def classify_group(group):\n",
    "    if group['dup_count'].iloc[0] > 3 and not is_same_timestamp(group):\n",
    "        return 'bulk_order'\n",
    "    elif is_same_timestamp(group) and group['dup_count'].iloc[0] > 1:\n",
    "        return 'error'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "df['dup_status'] = df.groupby('dup_key').apply(classify_group).reset_index(drop=True)\n",
    "\n",
    "def handle_duplicates(df):\n",
    "    cleaned = pd.DataFrame()\n",
    "    for key, group in df.groupby('dup_key'):\n",
    "        status = group['dup_status'].iloc[0]\n",
    "        if status == 'bulk_order':\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "        elif status == 'error':\n",
    "            cleaned = pd.concat([cleaned, group.head(1)])\n",
    "        elif status == 'uncertain':\n",
    "            group['flag_for_review'] = True\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "    return cleaned.reset_index(drop=True)\n",
    "\n",
    "df = handle_duplicates(df)\n",
    "print(\"üîÅ Smart duplicate handling applied (bulk, error, uncertain).\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Q9: Detect and Fix Outlier Prices (Optimized Version)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Step 1: Compute IQR bounds (fallback rule)\n",
    "Q1 = df['original_price_inr'].quantile(0.25)\n",
    "Q3 = df['original_price_inr'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "\n",
    "# Step 2: Define logical price ranges by subcategory\n",
    "subcategory_price_ranges = {\n",
    "    'smartphones': (5000, 100000),\n",
    "    'smart_watch': (500, 15000),\n",
    "    'audio': (300, 20000),\n",
    "    'tablets': (5000, 60000),\n",
    "    'laptops': (20000, 150000),\n",
    "    'tv_&_entertainment': (10000, 150000),\n",
    "    'home_appliances': (2000, 80000),\n",
    "    'accessories': (100, 10000)\n",
    "}\n",
    "\n",
    "# Step 3: Correction function\n",
    "def correct_price(row):\n",
    "    price = row['original_price_inr']\n",
    "    if pd.isna(price):\n",
    "        return price  # skip NaN\n",
    "    \n",
    "    subcat = str(row.get('subcategory', '')).strip().lower().replace(' ', '_')\n",
    "    expected = subcategory_price_ranges.get(subcat)\n",
    "    \n",
    "    # Rule 1: Subcategory-based correction\n",
    "    if expected:\n",
    "        min_p, max_p = expected\n",
    "        if price > max_p * 10:      # unusually high\n",
    "            return price / 100\n",
    "        elif price < min_p / 10:    # unusually low\n",
    "            return price * 100\n",
    "    \n",
    "    # Rule 2: Generic statistical correction\n",
    "    if price > upper_bound * 50:   # extreme high outlier (e.g., 100x mistake)\n",
    "        return price / 100\n",
    "    elif price < lower_bound / 50: # extreme low outlier\n",
    "        return price * 100\n",
    "    \n",
    "    return price\n",
    "\n",
    "# Step 4: Apply the correction efficiently\n",
    "df['original_price_inr'] = df.apply(correct_price, axis=1)\n",
    "\n",
    "print(\"üìà Outlier prices detected and corrected using statistical + category rules.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Q10: Standardize Payment Methods\n",
    "# ----------------------------------------\n",
    "df[\"payment_method\"] = df[\"payment_method\"].astype(str).str.lower().replace({\n",
    "    \"upi\": \"UPI\",\n",
    "    \"phonepe\": \"UPI\",\n",
    "    \"googlepay\": \"UPI\",\n",
    "    \"credit_card\": \"Credit Card\",\n",
    "    \"cc\": \"Credit Card\",\n",
    "    \"debit_card\": \"Debit Card\",\n",
    "    \"cod\": \"Cash On Delivery\",\n",
    "    \"c.o.d\": \"Cash On Delivery\"\n",
    "})\n",
    "print(\"üí≥ Payment methods standardized.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# üßÆ Handle Missing Values (Age, Festival, Delivery)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def convert_age_group(value):\n",
    "    \"\"\"\n",
    "    Convert age range formats like '18-25', '26-35', '55+' into numeric averages.\n",
    "    Handle blanks and unknowns as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"unknown\", \"na\", \"n/a\", \"none\", \"\", \"missing\"]:\n",
    "        return np.nan\n",
    "    if '-' in value:\n",
    "        parts = value.replace('years', '').split('-')\n",
    "        nums = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(nums) if nums else np.nan\n",
    "    if '+' in value:\n",
    "        num = value.replace('+', '').replace('years', '').strip()\n",
    "        if num.isdigit():\n",
    "            return float(num) + 5  # assume midpoint\n",
    "        return np.nan\n",
    "    if value.replace('.', '', 1).isdigit():\n",
    "        return float(value)\n",
    "    return np.nan\n",
    "\n",
    "# Apply to age column\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].apply(convert_age_group)\n",
    "avg_age = round(df[\"customer_age_group\"].mean())\n",
    "df[\"customer_age_group\"].fillna(avg_age, inplace=True)\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].astype(int)\n",
    "print(f\"üë§ Age column cleaned. Missing and unknown values filled with average: {avg_age}\")\n",
    "\n",
    "# Festival name fill\n",
    "df[\"festival_name\"].fillna(\"Unknown\", inplace=True)\n",
    "print(\"üéâ Festival names missing values filled with 'Unknown'.\")\n",
    "\n",
    "# Delivery charges fill\n",
    "df[\"delivery_charges\"].fillna(0, inplace=True)\n",
    "print(\"üí∞ Delivery charges missing values replaced with 0.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# ‚úÖ Final Checks & Save Cleaned Dataset\n",
    "# ----------------------------------------\n",
    "df.info()\n",
    "\n",
    "output_path = r\"C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2024_cleaned.csv\"\n",
    "\n",
    "# ‚úÖ Ensure output folder exists before saving\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "print(\"‚úÖ Data Cleaning Completed & Saved Successfully:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb47bb9d",
   "metadata": {},
   "source": [
    "### 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faedf193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded: (77385, 34)\n",
      "üóìÔ∏è Date column cleaned.\n",
      "üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\n",
      "üí∞ Price columns cleaned and converted to numeric.\n",
      "‚≠ê Ratings standardized to numeric scale.\n",
      "üèôÔ∏è City names standardized.\n",
      "üîò Boolean columns standardized to True/False.\n",
      "üõí Product categories standardized.\n",
      "üöö Delivery days cleaned and standardized.\n",
      "üîÅ Smart duplicate handling applied (bulk, error, uncertain).\n",
      "üìà Outlier prices detected and corrected using statistical + category rules.\n",
      "üí≥ Payment methods standardized.\n",
      "üë§ Age column cleaned. Missing and unknown values filled with average: 33\n",
      "üéâ Festival names missing values filled with 'Unknown'.\n",
      "üí∞ Delivery charges missing values replaced with 0.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77381 entries, 0 to 77380\n",
      "Data columns (total 38 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   transaction_id          77381 non-null  object \n",
      " 1   order_date              77381 non-null  object \n",
      " 2   customer_id             77381 non-null  object \n",
      " 3   product_id              77381 non-null  object \n",
      " 4   product_name            77381 non-null  object \n",
      " 5   category                77381 non-null  object \n",
      " 6   subcategory             77381 non-null  object \n",
      " 7   brand                   77381 non-null  object \n",
      " 8   original_price_inr      75119 non-null  float64\n",
      " 9   discount_percent        77381 non-null  float64\n",
      " 10  discounted_price_inr    77381 non-null  float64\n",
      " 11  quantity                77381 non-null  int64  \n",
      " 12  subtotal_inr            77381 non-null  float64\n",
      " 13  delivery_charges        77381 non-null  float64\n",
      " 14  final_amount_inr        77381 non-null  float64\n",
      " 15  customer_city           77381 non-null  object \n",
      " 16  customer_state          77381 non-null  object \n",
      " 17  customer_tier           77381 non-null  object \n",
      " 18  customer_spending_tier  77381 non-null  object \n",
      " 19  customer_age_group      77381 non-null  int64  \n",
      " 20  payment_method          77381 non-null  object \n",
      " 21  delivery_days           77381 non-null  float64\n",
      " 22  delivery_type           77381 non-null  object \n",
      " 23  is_prime_member         77381 non-null  bool   \n",
      " 24  is_festival_sale        77381 non-null  bool   \n",
      " 25  festival_name           77381 non-null  object \n",
      " 26  customer_rating         77381 non-null  float64\n",
      " 27  return_status           77381 non-null  object \n",
      " 28  order_month             77381 non-null  int64  \n",
      " 29  order_year              77381 non-null  int64  \n",
      " 30  order_quarter           77381 non-null  int64  \n",
      " 31  product_weight_kg       77381 non-null  float64\n",
      " 32  is_prime_eligible       77381 non-null  bool   \n",
      " 33  product_rating          77381 non-null  float64\n",
      " 34  dup_key                 77381 non-null  object \n",
      " 35  dup_count               77381 non-null  int64  \n",
      " 36  dup_status              77000 non-null  object \n",
      " 37  flag_for_review         76996 non-null  object \n",
      "dtypes: bool(3), float64(10), int64(6), object(19)\n",
      "memory usage: 20.9+ MB\n",
      "‚úÖ Data Cleaning Completed & Saved Successfully: C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2025_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# üßπ Amazon India Data Cleaning \n",
    "# Author: Desikan\n",
    "# Project: Amazon India 10-Year Sales Analytics\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # hide pandas 3.0 warnings\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# ----------------------------------------\n",
    "file_path = r\"C:\\Users\\desik\\Downloads\\Amazon raw dataset\\amazon_india_2025.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"‚úÖ Dataset Loaded:\", df.shape)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3Ô∏è‚É£ Q1: Clean and Standardize Dates\n",
    "# ----------------------------------------\n",
    "def clean_date(date_input):\n",
    "    try:\n",
    "        parsed_date = parser.parse(str(date_input), dayfirst=True)\n",
    "        return parsed_date.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"order_date\"] = df[\"order_date\"].apply(clean_date)\n",
    "print(\"üóìÔ∏è Date column cleaned.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4Ô∏è‚É£ Q2: Clean and Standardize Price Columns (Improved Version)\n",
    "# ----------------------------------------\n",
    "import re\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_price(value):\n",
    "    try:\n",
    "        value = str(value).strip()\n",
    "        # Remove currency symbols and unwanted characters\n",
    "        value = re.sub(r'[‚ÇπRs√¢‚Äö¬π]', '', value, flags=re.IGNORECASE)\n",
    "        value = value.replace(',', '')\n",
    "        \n",
    "        # Handle text like 'Price on Request' or blanks\n",
    "        if not re.match(r'^-?\\d+(\\.\\d+)?$', value):\n",
    "            return pd.NA\n",
    "        \n",
    "        # Convert to float and make sure negatives are positive\n",
    "        return abs(float(value))\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply cleaning to all relevant columns\n",
    "price_cols = [\"original_price_inr\", \"discounted_price_inr\", \"final_amount_inr\", \"delivery_charges\"]\n",
    "\n",
    "for col in price_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_price)\n",
    "\n",
    "print(\"üí∞ Price columns cleaned ‚Äî currency symbols removed, negatives corrected, and non-numerics handled.\")\n",
    "\n",
    "print(\"üí∞ Price columns cleaned and converted to numeric.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5Ô∏è‚É£ Q3: Standardize Ratings (1.0 - 5.0)\n",
    "# ----------------------------------------\n",
    "def clean_rating(value):\n",
    "    try:\n",
    "        val = str(value).lower().replace(\"stars\", \"\").replace(\"/5\", \"\").replace(\"/5.0\", \"\").strip()\n",
    "        return float(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].apply(clean_rating)\n",
    "df[\"product_rating\"] = df[\"product_rating\"].apply(clean_rating)\n",
    "df[\"customer_rating\"] = df[\"customer_rating\"].fillna(df[\"customer_rating\"].median())\n",
    "print(\"‚≠ê Ratings standardized to numeric scale.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6Ô∏è‚É£ Q4: Standardize City Names\n",
    "# ----------------------------------------\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype(str).str.title().str.strip()\n",
    "city_mapping = {\n",
    "    'ahmedabad': 'Ahmedabad',\n",
    "    'aligarh': 'Aligarh',\n",
    "    'allahabad': 'Allahabad',\n",
    "    'bangalore': 'Bengaluru',\n",
    "    'banglore': 'Bengaluru',\n",
    "    'bengalore': 'Bengaluru',\n",
    "    'bengaluru': 'Bengaluru',\n",
    "    'bhubaneswar': 'Bhubaneswar',\n",
    "    'bombay': 'Mumbai',\n",
    "    'calcutta': 'Kolkata',\n",
    "    'chandigarh': 'Chandigarh',\n",
    "    'chenai': 'Chennai',\n",
    "    'chennai': 'Chennai',\n",
    "    'coimbatore': 'Coimbatore',\n",
    "    'customer_city': 'Unknown',\n",
    "    'delhi': 'Delhi',\n",
    "    'delhi ncr': 'Delhi',\n",
    "    'new delhi': 'Delhi',\n",
    "    'gorakhpur': 'Gorakhpur',\n",
    "    'hyderabad': 'Hyderabad',\n",
    "    'indore': 'Indore',\n",
    "    'jaipur': 'Jaipur',\n",
    "    'kanpur': 'Kanpur',\n",
    "    'kochi': 'Kochi',\n",
    "    'kolkata': 'Kolkata',\n",
    "    'lucknow': 'Lucknow',\n",
    "    'ludhiana': 'Ludhiana',\n",
    "    'madras': 'Chennai',\n",
    "    'meerut': 'Meerut',\n",
    "    'moradabad': 'Moradabad',\n",
    "    'mumba': 'Mumbai',\n",
    "    'mumbai': 'Mumbai',\n",
    "    'nagpur': 'Nagpur',\n",
    "    'patna': 'Patna',\n",
    "    'pune': 'Pune',\n",
    "    'saharanpur': 'Saharanpur',\n",
    "    'surat': 'Surat',\n",
    "    'vadodara': 'Vadodara',\n",
    "    'varanasi': 'Varanasi',\n",
    "    'visakhapatnam': 'Visakhapatnam'\n",
    "}\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(city_mapping)\n",
    "print(\"üèôÔ∏è City names standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7Ô∏è‚É£ Q5: Clean Boolean Columns\n",
    "# ----------------------------------------\n",
    "bool_cols = [\"is_prime_member\", \"is_prime_eligible\", \"is_festival_sale\"]\n",
    "\n",
    "for col in bool_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .replace({\n",
    "            \"yes\": True, \"true\": True, \"1\": True, \"y\": True,\n",
    "            \"no\": False, \"false\": False, \"0\": False, \"n\": False\n",
    "        })\n",
    "    )\n",
    "    df[col] = df[col].astype(bool)\n",
    "\n",
    "print(\"üîò Boolean columns standardized to True/False.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 8Ô∏è‚É£ Q6: Standardize Product Categories\n",
    "# ----------------------------------------\n",
    "df[\"category\"] = df[\"category\"].astype(str).str.title().str.strip()\n",
    "category_mapping = {\n",
    "    'electronics': 'Electronics',\n",
    "    'electronic': 'Electronics',\n",
    "    'electronics & accessories': 'Electronics',\n",
    "    'electronicss': 'Electronics'\n",
    "}\n",
    "df[\"category\"] = df[\"category\"].replace(category_mapping)\n",
    "print(\"üõí Product categories standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 9Ô∏è‚É£ Q7: Clean Delivery Days\n",
    "# ----------------------------------------\n",
    "def clean_delivery_days(x):\n",
    "    x = str(x).lower()\n",
    "    if \"same\" in x:\n",
    "        return 0\n",
    "    elif \"-\" in x:\n",
    "        parts = x.replace(\"days\", \"\").split(\"-\")\n",
    "        parts = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(parts) if parts else np.nan\n",
    "    elif x.replace('.', '', 1).isdigit():\n",
    "        return float(x)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].apply(clean_delivery_days)\n",
    "df.loc[df[\"delivery_days\"] < 0, \"delivery_days\"] = np.nan\n",
    "df.loc[df[\"delivery_days\"] > 30, \"delivery_days\"] = np.nan\n",
    "df[\"delivery_days\"] = df[\"delivery_days\"].fillna(df[\"delivery_days\"].median())\n",
    "print(\"üöö Delivery days cleaned and standardized.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# üîü Q8: Handle Duplicate Transactions\n",
    "# ----------------------------------------\n",
    "# Create composite key\n",
    "df['dup_key'] = df[['customer_id', 'product_id', 'order_date', 'final_amount_inr']].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# Count occurrences\n",
    "dup_counts = df['dup_key'].value_counts().to_dict()\n",
    "df['dup_count'] = df['dup_key'].map(dup_counts)\n",
    "\n",
    "def is_same_timestamp(group):\n",
    "    return group['order_date'].nunique() == 1\n",
    "\n",
    "def classify_group(group):\n",
    "    if group['dup_count'].iloc[0] > 3 and not is_same_timestamp(group):\n",
    "        return 'bulk_order'\n",
    "    elif is_same_timestamp(group) and group['dup_count'].iloc[0] > 1:\n",
    "        return 'error'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "df['dup_status'] = df.groupby('dup_key').apply(classify_group).reset_index(drop=True)\n",
    "\n",
    "def handle_duplicates(df):\n",
    "    cleaned = pd.DataFrame()\n",
    "    for key, group in df.groupby('dup_key'):\n",
    "        status = group['dup_status'].iloc[0]\n",
    "        if status == 'bulk_order':\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "        elif status == 'error':\n",
    "            cleaned = pd.concat([cleaned, group.head(1)])\n",
    "        elif status == 'uncertain':\n",
    "            group['flag_for_review'] = True\n",
    "            cleaned = pd.concat([cleaned, group])\n",
    "    return cleaned.reset_index(drop=True)\n",
    "\n",
    "df = handle_duplicates(df)\n",
    "print(\"üîÅ Smart duplicate handling applied (bulk, error, uncertain).\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Q9: Detect and Fix Outlier Prices (Optimized Version)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Step 1: Compute IQR bounds (fallback rule)\n",
    "Q1 = df['original_price_inr'].quantile(0.25)\n",
    "Q3 = df['original_price_inr'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "\n",
    "# Step 2: Define logical price ranges by subcategory\n",
    "subcategory_price_ranges = {\n",
    "    'smartphones': (5000, 100000),\n",
    "    'smart_watch': (500, 15000),\n",
    "    'audio': (300, 20000),\n",
    "    'tablets': (5000, 60000),\n",
    "    'laptops': (20000, 150000),\n",
    "    'tv_&_entertainment': (10000, 150000),\n",
    "    'home_appliances': (2000, 80000),\n",
    "    'accessories': (100, 10000)\n",
    "}\n",
    "\n",
    "# Step 3: Correction function\n",
    "def correct_price(row):\n",
    "    price = row['original_price_inr']\n",
    "    if pd.isna(price):\n",
    "        return price  # skip NaN\n",
    "    \n",
    "    subcat = str(row.get('subcategory', '')).strip().lower().replace(' ', '_')\n",
    "    expected = subcategory_price_ranges.get(subcat)\n",
    "    \n",
    "    # Rule 1: Subcategory-based correction\n",
    "    if expected:\n",
    "        min_p, max_p = expected\n",
    "        if price > max_p * 10:      # unusually high\n",
    "            return price / 100\n",
    "        elif price < min_p / 10:    # unusually low\n",
    "            return price * 100\n",
    "    \n",
    "    # Rule 2: Generic statistical correction\n",
    "    if price > upper_bound * 50:   # extreme high outlier (e.g., 100x mistake)\n",
    "        return price / 100\n",
    "    elif price < lower_bound / 50: # extreme low outlier\n",
    "        return price * 100\n",
    "    \n",
    "    return price\n",
    "\n",
    "# Step 4: Apply the correction efficiently\n",
    "df['original_price_inr'] = df.apply(correct_price, axis=1)\n",
    "\n",
    "print(\"üìà Outlier prices detected and corrected using statistical + category rules.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Q10: Standardize Payment Methods\n",
    "# ----------------------------------------\n",
    "df[\"payment_method\"] = df[\"payment_method\"].astype(str).str.lower().replace({\n",
    "    \"upi\": \"UPI\",\n",
    "    \"phonepe\": \"UPI\",\n",
    "    \"googlepay\": \"UPI\",\n",
    "    \"credit_card\": \"Credit Card\",\n",
    "    \"cc\": \"Credit Card\",\n",
    "    \"debit_card\": \"Debit Card\",\n",
    "    \"cod\": \"Cash On Delivery\",\n",
    "    \"c.o.d\": \"Cash On Delivery\"\n",
    "})\n",
    "print(\"üí≥ Payment methods standardized.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# üßÆ Handle Missing Values (Age, Festival, Delivery)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def convert_age_group(value):\n",
    "    \"\"\"\n",
    "    Convert age range formats like '18-25', '26-35', '55+' into numeric averages.\n",
    "    Handle blanks and unknowns as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"unknown\", \"na\", \"n/a\", \"none\", \"\", \"missing\"]:\n",
    "        return np.nan\n",
    "    if '-' in value:\n",
    "        parts = value.replace('years', '').split('-')\n",
    "        nums = [float(p) for p in parts if p.replace('.', '', 1).isdigit()]\n",
    "        return np.mean(nums) if nums else np.nan\n",
    "    if '+' in value:\n",
    "        num = value.replace('+', '').replace('years', '').strip()\n",
    "        if num.isdigit():\n",
    "            return float(num) + 5  # assume midpoint\n",
    "        return np.nan\n",
    "    if value.replace('.', '', 1).isdigit():\n",
    "        return float(value)\n",
    "    return np.nan\n",
    "\n",
    "# Apply to age column\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].apply(convert_age_group)\n",
    "avg_age = round(df[\"customer_age_group\"].mean())\n",
    "df[\"customer_age_group\"].fillna(avg_age, inplace=True)\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].astype(int)\n",
    "print(f\"üë§ Age column cleaned. Missing and unknown values filled with average: {avg_age}\")\n",
    "\n",
    "# Festival name fill\n",
    "df[\"festival_name\"].fillna(\"Unknown\", inplace=True)\n",
    "print(\"üéâ Festival names missing values filled with 'Unknown'.\")\n",
    "\n",
    "# Delivery charges fill\n",
    "df[\"delivery_charges\"].fillna(0, inplace=True)\n",
    "print(\"üí∞ Delivery charges missing values replaced with 0.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# ‚úÖ Final Checks & Save Cleaned Dataset\n",
    "# ----------------------------------------\n",
    "df.info()\n",
    "\n",
    "output_path = r\"C:\\Users\\desik\\Desktop\\cleaned output\\amazon_india_2025_cleaned.csv\"\n",
    "\n",
    "# ‚úÖ Ensure output folder exists before saving\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "print(\"‚úÖ Data Cleaning Completed & Saved Successfully:\", output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
